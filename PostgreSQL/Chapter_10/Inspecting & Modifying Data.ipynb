{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4167f54-4adf-49ea-bc9e-836dbc0a1803",
   "metadata": {},
   "source": [
    "# Inspecting & Modifying Data\n",
    "\n",
    "Dirty data can have multiple origins. Converting data from one file type to another or giving a column the wrong data type can cause information to be lost. People can also be careless when inputting or editting data, leaving behind typos & spelling inconsistencies. Whatever the cause may be, dirty data is the bane of the data analyst.\n",
    "\n",
    "Being able to examine data to assess its quality & how to modify data & tables to make analysis easier. The ability to make changes to data & tables gives us options for updating or adding new information to our database as it becomes available, elevating our database from a static collection to a living record."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8876f7f-fb77-45d5-920d-9b062ee7ae7d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b523d9-1415-4a38-8f06-0f08b8076424",
   "metadata": {},
   "source": [
    "# Importing Data on Meat, Poultry, & Egg Producers\n",
    "\n",
    "For this lesson, we'll use a directory of US meat, poultry, & egg producers. The data we'll use comes from [https://data.gov/](https://data.gov/), a website run by the US federal government that catalogs thousands of datasets from various federal agencies. You'll find the file along with the other resources downloaded for this course.\n",
    "\n",
    "To import the file into PostgreSQL, we'll create a table called `meat_poultry_egg_establishments` & use `COPY` to add the CSV file to the table.\n",
    "\n",
    "```\n",
    "CREATE TABLE meat_poultry_egg_establishments (\n",
    "    establishment_number text\n",
    "        CONSTRAINT est_number_key PRIMARY KEY,\n",
    "    company text,\n",
    "    street text,\n",
    "    city text,\n",
    "    st text,\n",
    "    zip text,\n",
    "    phone text,\n",
    "    grant_date date,\n",
    "    activities text,\n",
    "    dbas text\n",
    ");\n",
    "\n",
    "COPY meat_poultry_egg_establishments\n",
    "FROM '/YourDirectory/MPI_Directory_by_Establishment_Name.csv'\n",
    "WITH (FORMAT CSV, HEADER);\n",
    "\n",
    "CREATE INDEX compnay_idx\n",
    "ON meat_poultry_egg_establishments (company);\n",
    "```\n",
    "\n",
    "The table has 10 columns. We add a natural primary key constraint to the `establishment_number` column, which will hold unique values that identify each establishment. Most of the remaining columns relate to the company's name & location. We set most columns to `text`. We import the CSV & then create an index on the `company` column to speed up searches for particular companies.\n",
    "\n",
    "For practice, let's use the `count()` aggregate function to check how many rows are in the `meat_poultry_egg_establishments` table:\n",
    "\n",
    "```\n",
    "SELECT count(*)\n",
    "FROM meat_poultry_egg_establishments;\n",
    "```\n",
    "\n",
    "<img src = \"Row Count Check on meat_poultry_egg_establishments Table.png\" width = \"600\" style = \"margin:auto\"/>\n",
    "\n",
    "The result should show 6,287 rows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ec4e09-fdaa-4934-a04c-575ac11279fb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10f7f6c-5451-4b1c-9e35-153b67b442a7",
   "metadata": {},
   "source": [
    "# Interviewing the Dataset\n",
    "\n",
    "Let's interview the dataset to discover its details. The `meat_poultry_egg_establishments` table's rows describe food producers. At first glance, we might assume that each company in each row operates at a distinct address. But it's never safe to assume in data analysis, so let's run some checks.\n",
    "\n",
    "```\n",
    "SELECT company, street, city, st,\n",
    "       count(*) AS address_count\n",
    "FROM meat_poultry_egg_establishments\n",
    "GROUP BY company, street, city, st\n",
    "HAVING count(*) > 1\n",
    "ORDER BY company, street, city, st;\n",
    "```\n",
    "\n",
    "Here, we group companies by unique combinations of the `company`, `street`, `city`, & `st` columns. Then we use `count(*)`, which returns the number of rows for each combination of those columns & gives it the alias `address_count`. Using the `HAVING` clause, we filter the results to show only cases where more than one row has the same combination of values. This should return all duplicate addresses for a company.\n",
    "\n",
    "The query returns 23 rows, which means there are close to two dozen cases where the same company is listed multiple times at the same address:\n",
    "\n",
    "<img src = \"Finding Multiple Companies at the Same Address.png\" width = \"600\" style = \"margin:auto\"/>\n",
    "\n",
    "This is not necessarily a problem. There may be valid reasons for a company to appear multiple times at the same address. For example, two types of processing plants could exist with the same name. On the other hand, we may have found data entry errors. Either way, it's wise to eliminate concerns about the validity of a dataset before relying on it. This result should prompt use to investigate individual cases before we draw conclusions. However, this dataset has other issues that we need to look at before we get meaningful data from it.\n",
    "\n",
    "## Check for Missing Values\n",
    "\n",
    "We'll also check whether we have values from all states & whether any rows are missing a state code. We'll use the aggregate function `count()` along with `GROUP BY` to determine this.\n",
    "\n",
    "```\n",
    "SELECT st,\n",
    "       count(*) AS st_count\n",
    "FROM meat_poultry_egg_establishments\n",
    "GROUP BY st\n",
    "ORDER BY st;\n",
    "```\n",
    "\n",
    "The query is a simple count that tallies the number of times each state postal code (`st`) appears in the table. Your result should include 57 rows, grouped by the state postal code in the column `st`. Why more than 50 US states? Because the data includes Puerto Rico & other unincorporated US territories, such as Guam & American Samoa. Alaska (`AK`) is at the top of the results with a count of `17` establishments:\n",
    "\n",
    "<img src = \"Grouping & Counting States.png\" width = \"600\" style = \"margin:auto\"/>\n",
    "\n",
    "However, the row at the botom of the list has a `NULL` value in the `st` column & a `3` in `st_count`. That means three rows have a `NULL` in `st`. To see the details of those facilities, let's query those rows.\n",
    "\n",
    "We'll add a `WHERE` clause with the `st` column & the `IS NULL` keywords to find which rows are missing a state code.\n",
    "\n",
    "```\n",
    "SELECT establishment_number,\n",
    "       company,\n",
    "       city,\n",
    "       st,\n",
    "       zip\n",
    "FROM meat_poultry_egg_establishments\n",
    "WHERE st IS NULL;\n",
    "```\n",
    "\n",
    "This query returns three rows that don't have a value in the `st` column:\n",
    "\n",
    "<img src = \"Using IS NULL to Find Missing Values in the st Column.png\" width = \"600\" style = \"margin:auto\"/>\n",
    "\n",
    "This is a problem, because any counts that include the `st` column will be incorrect, such as the number of establishments per state. When we spot an error such as this, it's worth making a quick visual check of the original file. We can confirm that there is no state listed in those rows in the file, so the error is organic to the data, not one introduced during import.\n",
    "\n",
    "We'll have to add missing values to the `st` column to clean up this table.\n",
    "\n",
    "## Checking for Inconsistent Data Values\n",
    "\n",
    "Inconsistent data is another factor that can hamper our analysis. We can check for inconsistently entered data within a column by using `GROUP BY` with `count()`. When you scan the unduplicated values in the results, you might be able to spot variations in the spelling of names or other attributes.\n",
    "\n",
    "For example, many of the 6,200 companies in our table are multiple locations owned by just a few multinational food corporations, such as Cargill or Tyson Foods. To find out how many locations each company owns, we count the values in the `company` column. Let's see what happens when we do.\n",
    "\n",
    "```\n",
    "SELECT company,\n",
    "       count(*) AS company_count\n",
    "FROM meat_poultry_egg_establishments\n",
    "GROUP BY company\n",
    "ORDER BY company ASC;\n",
    "```\n",
    "\n",
    "At least four different spellings are shown for seven establishments that are likely owned by the same company. It would help to standardise the names so all the items counted or summed are grouped properly.\n",
    "\n",
    "<img src = \"Using GROUP BY & count() to Find Inconsistent Company Names.png\" width = \"600\" style = \"margin:auto\"/>\n",
    "\n",
    "## Checking for Malformed Values Using length()\n",
    "\n",
    "It's a good idea to check for unexpected values in a column that should be consistently formatted. For example, each entry in the `zip` column in the `meat_poultry_egg_establishments` table should be formatted in the style of US ZIP codes with five digits. However, that's not what is in our dataset.\n",
    "\n",
    "Zip codes are 5 digit values, however some zip codes lose their leading zeros because of its `integer` data type. We can see this error when we run the below code. The example introduced `length()`, is a *string function* that counts the number of characters in a string. We combine `length()` with `count()` & `GROUP BY` to determine how many rows have five characters in the `zip` field & how many to have a value other than five. To make it easy to scan the results, we use `length()` in the `ORDER BY` clause.\n",
    "\n",
    "```\n",
    "SELECT length(zip),\n",
    "       count(*) AS length_count\n",
    "FROM meat_poultry_egg_establishments\n",
    "GROUP BY length(zip)\n",
    "ORDER BY length(zip) ASC;\n",
    "```\n",
    "\n",
    "The results confirm the formatting error. As you can see, `496` of the ZIP codes are four characters long, & `86` are three characters long, which likely means these numbers originally had two leading zeros erroneously eliminated.\n",
    "\n",
    "<img src = \"Using length() & count() to Test the zip Column.png\" width = \"600\" style = \"margin:auto\"/>\n",
    "\n",
    "Using the `WHERE` clause, we can see which states these shortened zip code correspond to.\n",
    "\n",
    "```\n",
    "SELECT st,\n",
    "       count(*) AS st_count\n",
    "FROM meat_poultry_egg_establishments\n",
    "WHERE length(zip) < 5\n",
    "GROUP BY st\n",
    "ORDER BY st ASC;\n",
    "```\n",
    "\n",
    "We use the `length()` function inside the `WHERE` clause to return a count of rows where the zip code is less than five characters for each state code. The result is what we would expect. The states are largely in the Northeast region of the United States where zip codes often start with zero.\n",
    "\n",
    "<img src = \"Filtering with length() to Find Short zip Values.png\" width = \"600\" style = \"margin:auto\"/>\n",
    "\n",
    "Obviously, we don't want this error to persist, so we'll add it to our list of items to correct. So far, we need to correct the following issues in our dataset:\n",
    "\n",
    "1. Missing values for three rows in the `st` column\n",
    "2. Inconsistent spelling of at least one company's name\n",
    "3. Inaccurate ZIP codes\n",
    "\n",
    "We'll look at how to use SQL to fix these issues by modifying the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e718e3f-ed34-4745-8287-ad3fc9279344",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d067b9-52a3-4cc7-bc8e-e064eada17af",
   "metadata": {},
   "source": [
    "# Modifying Tables, Columns, & Data\n",
    "\n",
    "Almost nothing in a database, from tables to columns & the data types & values they contain, is set in concrete after it's created. As your needs change, you can use SQL to add columns to a table, change data types on existing column, & edit values. Given the issues we discovered in the `meat_poultry_egg_establishments` table, being able to modify our database will come in handy.\n",
    "\n",
    "We'll use two SQL commands. The first, `ALTER TABLE`, is part of ANSI SQL standard & provides options to `ADD COLUMN`, `ALTER COLUMN` & `DROP COLUMN`, among others.\n",
    "\n",
    "The second command, `UPDATE`, also included in the SQL standard, allows you to change values in a table's columns. You can supply criteria using `WHERE` to choose which rows to update.\n",
    "\n",
    "We'll explore the basic syntax & options for both commands & use them to fix the issues in our dataset.\n",
    "\n",
    "## Modifying Tables with ALTER TABLE\n",
    "\n",
    "We can use the `ALTER TABLE` statement to modify the structure of tables. The following examples show standard ANSI SQL syntax for common operations, starting with the code for adding a column to a table:\n",
    "\n",
    "```\n",
    "ALTER TABLE table ADD COLUMN column data_type;\n",
    "```\n",
    "\n",
    "We can remove a column with the following syntax:\n",
    "\n",
    "```\n",
    "ALTER TABLE table DROP COLUMN column;\n",
    "```\n",
    "\n",
    "To change the data type of a column, we would use this code:\n",
    "\n",
    "```\n",
    "ALTER TABLE table ALTER COLUMN column\n",
    "    SET DATA TYPE data_type;\n",
    "```\n",
    "\n",
    "We add a `NOT NULL` constraint to a column like so:\n",
    "\n",
    "```\n",
    "ALTER TABLE table ALTER COLUMN column SET NOT NULL;\n",
    "```\n",
    "\n",
    "Note that in PostgreSQL & some other systems, adding a constraint to the table causes all rows to be checked to see whether they comply with the constraint. If the table has millions of rows, this could take a while.\n",
    "\n",
    "Removing the `NOT NULL` constraint looks like this:\n",
    "\n",
    "```\n",
    "ALTER TABLE table ALTER COLUMN column DROP NOT NULL;\n",
    "```\n",
    "\n",
    "When you execute `ALTER TABLE` with the placeholders filled in, you should see a message that reads `ALTER TABLE` in the pgAdmin output screen. If an operation violates a constraint or if you attempt to change a column's data type & the existing values in the column won't conform to the new data type, PostgreSQL returns an error. But PostgreSQL won't give you any warning about deleting data when you drop a column, so use extra caution before dropping a column.\n",
    "\n",
    "## Modifying Values with UPDATE\n",
    "\n",
    "The `UPDATE` statement, part of the ANSI SQL standard, modifies the data in a column that meets a condition. It can be applied to all rows or a subset of rows. It's basic syntax for updating the data in every row in a column follows this form:\n",
    "\n",
    "```\n",
    "UPDATE table\n",
    "SET column = value;\n",
    "```\n",
    "\n",
    "We first pass `UPDATE` the name of the table. Then to `SET`, we pass the column we want to update. The new `value` to place in the column can be a string, number, the name of another column, or even a query or expression that generates a value. The new value must be compatible with the column data type.\n",
    "\n",
    "We can update values in multiple columns by adding additional columns & source values & separating each with a comma:\n",
    "\n",
    "```\n",
    "UPDATE table\n",
    "SET column_a = value,\n",
    "    column_b = value;\n",
    "```\n",
    "\n",
    "To restrict the update to particular rows, we add a `WHERE` clause with some criteria that must be met before the update can happen, such as rows where values equal to something or match a string:\n",
    "\n",
    "```\n",
    "UPDATE table\n",
    "SET column = value\n",
    "WHERE criteria\n",
    "```\n",
    "\n",
    "We can also update one table with values from another table. Standard ANSI SQL requires that we write a *subquery*, a query inside a query, to specify which values & rows to update.\n",
    "\n",
    "```\n",
    "UPDATE table\n",
    "SET column = (SELECT column\n",
    "              FROM table_b\n",
    "              WHERE table.column = table_b.column)\n",
    "WHERE EXISTS (SELECT column\n",
    "              FROM table_b\n",
    "              WHERE table.column = table_b.column);\n",
    "```\n",
    "\n",
    "The value portion of `SET`, inside the parentheses, is a subquery. A `SELECT` statement inside parentheses generates the value for the update by joining columns in both tables on matching row values. Similarly, the `WHERE EXISTS` clause uses a `SELECT` statement to ensure that we only update rows where both tables have matching values. If we didn't use `WHERE EXISTS` we might inadvertently see some values to `NULL` without planning to.\n",
    "\n",
    "Some database managers offer additional syntax from updating across tables. PostgreSQL supports the ANSI standard but also a similar syntax using a `FROM` clause:\n",
    "\n",
    "```\n",
    "UPDATE table\n",
    "SET column = table_b.column\n",
    "FROM table_b\n",
    "WHERE table.column = table_b.column;\n",
    "```\n",
    "\n",
    "When you execute an `UPDATE` statement, you'll get a message stating `UDPATE` along with the number of rows affected\n",
    "\n",
    "## Viewing Modified Data with RETURNING\n",
    "\n",
    "If you add an optional `RETURNING` clause to `UPDATE`, you can view the values that were modified without having to run a second, separate query. The syntax of the clause uses the `RETURNING` keyword followed by a list of columns or a wildcard in the same manner that we name columns following `SELECT`. Here's an example:\n",
    "\n",
    "```\n",
    "UPDATE table\n",
    "SET column_a = value\n",
    "RETURNING column_a, column_b, column_c;\n",
    "```\n",
    "\n",
    "Instead of just noting the number of rows modified, `RETURNING` directs the database to show the columns you specify for the rows modified. This is a PostgreSQL-specific implementation that we can also use with `INSERT` & `DELETE FROM`.\n",
    "\n",
    "## Creating Backup Tables\n",
    "\n",
    "Before modifying a table, it's a good idea to make a copy for reference & backup in case we accidently destroy some data. We can use a variation of the familiar `CREATE TABLE` statement to make a new table from the table we want to duplicate.\n",
    "\n",
    "```\n",
    "CREATE TABLE meat_poultry_egg_establishments_backup\n",
    "AS (SELECT *\n",
    "    FROM meat_poultry_egg_establishments;)\n",
    "```\n",
    "\n",
    "The result should be a pristine copy of your table with the new specified name. You can confirm this by counting the number of records in both tables at once:\n",
    "\n",
    "```\n",
    "SELECT (SELECT count(*)\n",
    "        FROM meat_poultry_egg_establishments) AS original,\n",
    "       (SELECT count(*)\n",
    "        FROM meat_poultry_egg_establishments_backup) AS backup;\n",
    "```\n",
    "\n",
    "The results should return the same count from both tables.\n",
    "\n",
    "<img src = \"Backing Up a Table.png\" width = \"600\" style = \"margin:auto\"/> \n",
    "\n",
    "If the counts match, you can be sure your backup table is an exact copy of the structure & contents of the original table. As an added measure & for easy reference, we'll use `ALTER TABLE` to make copies of column data within the table we're updating.\n",
    "\n",
    "## Restoring Missing Column Values\n",
    "\n",
    "Earlier, we revealed that three rows in the `meat_poultry_egg_establishments` table don't have a value in the `st` column. \n",
    "\n",
    "<img src = \"Using IS NULL to Find Missing Values in the st Column.png\" width = \"600\" style = \"margin:auto\"/>\n",
    "\n",
    "To get a complete count of establishments in each state, we need to fill those missing values using an `UPDATE` statement.\n",
    "\n",
    "### Creating a Column Copy\n",
    "\n",
    "Even though we've backed up this table, let's take extra caution & make a copy of the `st` column within the table so we still have the original data if we make some dire error somewhere. Let's create the copy & fill it with the existing `st` column values.\n",
    "\n",
    "```\n",
    "ALTER TABLE meat_poultry_egg_establishments\n",
    "ADD COLUMN st_copy text;\n",
    "\n",
    "UPDATE meat_poultry_egg_establishments\n",
    "SET st_copy = st;\n",
    "```\n",
    "\n",
    "The `ALTER TABLE` statement adds a column called `st_copy` using the same `text` data type as the original `st` column. Next, the `SET` clause in `UPDATE` fills our new `st_copy` column with the values in column `st`. Because we don't specify any criteria using `WHERE`, values in every row are updated, & PostgreSQL returns the message `UPDATE 6287`. Again, it's worth noting that on a very large table, this operation could take some time & also substantially increases the table's size. Making a column in addition to a table backup isn't entirely necessary, but if you're the patient cautious type, it can be worthwhile.\n",
    "\n",
    "We can confirm the values were copied properly with a simple `SELECT` query on both columns.\n",
    "\n",
    "```\n",
    "SELECT st, st_copy\n",
    "FROM meat_poultry_egg_establishments\n",
    "WHERE st IS DISTINCT FROM st_copy\n",
    "ORDER BY st;\n",
    "```\n",
    "\n",
    "To check for differences between values in the columns, we use `IS DISTINCT FROM` in the `WHERE` clause. We've used `DISTINCT` before to find unique values in a column; in this context, `IS DISTINCT` tests whether values in `st` & `st_copy` are different. This keeps us from having to scan every row ourselves. Running this query will return zero rows, meaning the values match throughout the table.\n",
    "\n",
    "<img src = \"Checking Values in the st & st_copy Columns.png\" width = \"600\" style = \"margin:auto\"/> \n",
    "\n",
    "Now, with our original data safely stored, we can update the three rows with missing state codes. This is now our in-table backup, so if something goes drastically wrong while we're updating the original column, we can easily copy the original data back in.\n",
    "\n",
    "### Updating Rows Where Values Are Missing\n",
    "\n",
    "To update those rows' missing values, we first find the values we need with a quick online search: Atlas Inspection is located in Minnesota; Hall-Namie Packing is in Alabama; & Jones Dairy is in Wisconsin. We add those states to the appropriate rows below.\n",
    "\n",
    "```\n",
    "UPDATE meat_poultry_egg_establishments\n",
    "SET st = 'MN'\n",
    "WHERE establishment_number = 'V18677A'\n",
    "RETURNING establishment_number, company, city, st, zip;\n",
    "\n",
    "UPDATE meat_poultry_egg_establishments\n",
    "SET st = 'AL'\n",
    "WHERE establishment_number = 'M45319+P45319'\n",
    "RETURNING establishment_number, company, city, st, zip;\n",
    "\n",
    "UPDATE meat_poultry_egg_establishments\n",
    "SET st = 'AL'\n",
    "WHERE establishment_number = 'M263A+P263A+V263A'\n",
    "RETURNING establishment_number, company, city, st, zip;\n",
    "```\n",
    "\n",
    "Because we want each `UPDATE` statement to affect a single row, we include a `WHERE` clause for each that identifies the company's unique `establishment_number`, which is the table's primary key. When we run the queries, PostgreSQL directs the database to show several columns from that row that was updated along with a temporary message stating the number of rows affected:\n",
    "\n",
    "<img src = \"Updating the st Column for Three Establishments.png\" width = \"600\" style = \"margin:auto\"/>\n",
    "\n",
    "If we rerun our code from before to find rows where `st` is `NULL`, the query should return nothing:\n",
    "\n",
    "```\n",
    "SELECT establishment_number,\n",
    "       company,\n",
    "       city,\n",
    "       st,\n",
    "       zip\n",
    "FROM meat_poultry_egg_establishments\n",
    "WHERE st IS NULL;\n",
    "```\n",
    "\n",
    "<img src = \"Rerunning IS NULL to Find Missing Values in the st Column.png\" width = \"600\" style = \"margin:auto\"/>\n",
    "\n",
    "### Restoring Original Values\n",
    "\n",
    "What happens if we botch an update by providing the wrong values or updating the wrong rows? We'll just copy the data back from either the full table backup or the column backup.\n",
    "\n",
    "```\n",
    "UPDATE meat_poultry_egg_establishments\n",
    "SET st = st_copy;\n",
    "\n",
    "UPDATE meat_poultry_egg_establishments AS original\n",
    "SET st = backup.st\n",
    "FROM meat_poultry_egg_establishments_backup AS backup\n",
    "WHERE original.establishment_number =\n",
    "    backup.establishment_number;\n",
    "```\n",
    "\n",
    "To restore the values from the backup column in `meat_poultry_egg_establishments`, run an `UPDATE` query that sets `st` to the values in `st_copy`. Both columns should again have the identical original values. Alternatively, we can create an `UPDATE` that sets `st` to values in the `st` column from the `meat_poultry_egg_establishments_backup` table we made before. This will obviate the fixes we made to add missing state values as well.\n",
    "\n",
    "## Updating Values for Consistency\n",
    "\n",
    "Earlier, we discovered several cases where a single company's name was entered inconsistently. These inconsistencies will hinder us if we want to aggregate data by company name, so we'll fix them.\n",
    "\n",
    "Here are the spelling variations of Armour-Eckrich Meats:\n",
    "\n",
    "<img src = \"Using GROUP BY & count() to Find Inconsistent Company Names.png\" width = \"600\" style = \"margin:auto\"/>\n",
    "\n",
    "We can standardise the spelling using an `UPDATE` statement. To protect our data, we'll create a new column for the standardised spellings, copy names in `company` into the new column, & work in the new column.\n",
    "\n",
    "```\n",
    "ALTER TABLE meat_poultry_egg_establishments\n",
    "ADD COLUMN company_standard text;\n",
    "\n",
    "UPDATE meat_poultry_egg_establishments\n",
    "SET company_standard = company;\n",
    "```\n",
    "\n",
    "Now, let's say we want any name in `company` that starts with the string `Armour` to appear in `company_standard` as `Armour_Eckrich Meats`. (This assumes we've checked all Armour entries & want to standardise them.)  The below code can update all rows matching the string `Armour` using `WHERE`.\n",
    "\n",
    "```\n",
    "UPDATE meat_poultry_egg_establishments\n",
    "SET company_standard = 'Armour-Eckrich Meats'\n",
    "WHERE company LIKE 'Armour%'\n",
    "RETURNING company, company_standard;\n",
    "```\n",
    "\n",
    "The important piece of this query is the `WHERE` clause that uses the `LIKE` keyword for case-sensitive pattern matching. Including the wildcard syntax `%` at the end of the string `Armour` updates all rows that start with those characters regardless of what comes after them. The clause lets us target all the varied spellings used for the company's name. The `RETURNING` clause causes the statement to provide the results of the updated `company_standard` column next to the original `company` column:\n",
    "\n",
    "<img src = \"Creating & Filling the company_standard Column.png\" width = \"600\" style = \"margin:auto\"/>\n",
    "\n",
    "The values for Armour-Eckrich in `company_standard` are now standardised with consistently spelling. To standardise other company names in the table, we would create an `UPDATE` statement for each case. We would also keep the original `company` column for reference.\n",
    "\n",
    "## Repairing ZIP Codes Using Concatenation\n",
    "\n",
    "Our final fix repairs values in the `zip` column that lost leading zeros. Zip codes in Puerto Rico & the US Virgin Islands begin with two zeros, so we need to restore two leading zeros to the values in `zip`. For the other states, located mostly in New England, we'll restored a single leading zero.\n",
    "\n",
    "We'll use `UPDATE` in conjunction with the double-pipe *string concatenation operator* (`||`). Concatenation combines two string values into one (it will also combine a string & a number into a string). For example, inserting `||` between the strings `abc` & `xyz` results in `abcxyz`. The double-pipe operator is a SQL standard for concatenation supported by PostgreSQL. You can use it in many contexts, such as `UPDATE` queries & `SELECT`, to provide custom output from existing as well as new data.\n",
    "\n",
    "First, let's make a backup copy of the `zip` column.\n",
    "\n",
    "```\n",
    "ALTER TABLE meat_poultry_egg_establishments\n",
    "ADD COLUMN zip_copy text;\n",
    "\n",
    "UPDATE meat_poultry_egg_establishments\n",
    "SET zip_copy = zip;\n",
    "```\n",
    "\n",
    "Next, we'll perform the first update.\n",
    "\n",
    "```\n",
    "UPDATE meat_poultry_egg_establishments\n",
    "SET zip = '00' || zip\n",
    "WHERE st IN ('PR', 'VI') AND length(zip) = 3;\n",
    "```\n",
    "\n",
    "We use `SET` to set the value in the `zip` column to the result of the concatenation of `00` & the existing value. We limit the `UPDATE` to only those rows where the `st` column has the state codes `PR` & `VI` using the `IN` comparison operator & add a test for rows where the length of `zip` is `3`. This entire statement will then only update the `zip` values for Puerto Rico & the Virgin Islands. \n",
    "\n",
    "Let's repair the remaining ZIP codes using a similar query.\n",
    "\n",
    "```\n",
    "UPDATE meat_poultry_egg_establishments\n",
    "SET zip = '0' || zip\n",
    "WHERE st IN ('CT', 'MA', 'ME', 'NH', 'NJ', 'RI', 'VT')\n",
    "    AND length(zip) = 4;\n",
    "```\n",
    "\n",
    "Now let's check our progress. Earlier, when we aggregated rows in the `zip` column by length, we found `86` rows with three characters & `496` with four. Using the same query now returns a more desirable results: all the rows have a five-digit ZIP code.\n",
    "\n",
    "```\n",
    "SELECT length(zip),\n",
    "       count(*) AS length_count\n",
    "FROM meat_poultry_egg_establishments\n",
    "GROUP BY length(zip)\n",
    "ORDER BY length(zip) ASC;\n",
    "```\n",
    "\n",
    "<img src = \"Modifying Codes in the zip Column Missing One Leading Zero.png\" width = \"600\" style = \"margin:auto\"/>\n",
    "\n",
    "## Updating Values Across Tables\n",
    "\n",
    "Earlier in this lesson: \"Modifying Values with UPDATE\", we saw the standard ANSI SQL & PostgreSQL-specific syntax for updating values in one table based on values in another. This syntax is particularly valuable in a relational database where primary keys & foreign keys establish table relationships. In those cases, we may need information in one table to update values in another table.\n",
    "\n",
    "Let's say we're setting an inspection deadline for each of the companies in our table. We want to do this by US regions, such as Northeast, Pacific, & so on, but those regional designations don't exist in our table. However, they do exist in the file *state_regions.csv*, that contains matching `st` state codes. Once we load that file into a table, we can use that data in an `UPDATE` statement. Let's begin with the New England region to see how this works.\n",
    "\n",
    "The below code contains the SQL statements to create a `state_regions` table & fill the table with data:\n",
    "\n",
    "```\n",
    "CREATE TABLE state_regions (\n",
    "    st text CONSTRAINT st_key PRIMARY KEY,\n",
    "    region text NOT NULL\n",
    ");\n",
    "\n",
    "COPY state_regions\n",
    "FROM '/YourDirectory/state_regions.csv'\n",
    "WITH (FORMAT CSV, HEADER);\n",
    "\n",
    "SELECT * FROM state_regions;\n",
    "```\n",
    "\n",
    "We'll create two columns in a `state_regions` table: one containing the two-character state code `st` & the other containing the `region` name. We set the primary key constraint to the `st` column, which holds a unique `st_key` value to identify each state. In the data we're importing, each state is present & assigned to a census region, & territories outside the United States are labeled as outlying areas. We'll update the table one region at a time.\n",
    "\n",
    "<img src = \"Creating & Filling a state_regions Table.png\" width = \"600\" style = \"margin:auto\"/>\n",
    "\n",
    "Next, let's return the `meat_poultry_egg_establishments` table, add a column for inspection dates, & then fill in that column with the New England States.\n",
    "\n",
    "```\n",
    "ALTER TABLE meat_poultry_egg_establishments\n",
    "ADD COLUMN inspection_deadline\n",
    "    timestamp with time zone;\n",
    "\n",
    "UPDATE meat_poultry_egg_establishments\n",
    "    AS establishments\n",
    "SET inspection_deadline = '2022-12-01 00:00 EST'\n",
    "WHERE EXISTS (\n",
    "    SELECT state_regions.region\n",
    "    FROM state_regions\n",
    "    WHERE establishments.st = state_regions.st\n",
    "      AND state_regions.region = 'New England'\n",
    ");\n",
    "```\n",
    "\n",
    "The `ALTER TABLE` statement creates the `inspection_deadline` column in the `meat_poultry_egg_establishments` table. In the `UPDATE` statement, we give the table an alias of `establishments` to make the code easier to read. Next, `SET` assigns a timestamp value of `2022-12-01 00:00 EST` to the new `inspection_deadline` column. Finally, `WHERE EXISTS` includes a subquery that connects the `meat_poultry_egg_establishments` table to the `state_regions` table we created & specifies which rows to update. The subquery (in parentheses, beginning with `SELECT`) looks for rows in the `state_regions` table where the `region` column matches the string `New England`. At the same time, it joins the `meat_poultry_egg_establishments` table with the `state_regions` table using the `st` column from both sides. In effect, the query is telling the databases to find all the `st` codes that correspond to the New England region & use those codes to filter the update.\n",
    "\n",
    "We can see the effect of the change with the below code:\n",
    "\n",
    "```\n",
    "SELECT st, inspection_deadline\n",
    "FROM meat_poultry_egg_establishments\n",
    "GROUP BY st, inspection_deadline\n",
    "ORDER BY st;\n",
    "```\n",
    "\n",
    "The results should show the updated inspection deadlines for all New England companies. The top of the output shows Connecticut has received a deadline timestamp, for example, but states outside New England remain `NULL` because we haven't updated them yet:\n",
    "\n",
    "<img src = \"Viewing Updated inspection_date Values.png\" width = \"600\" style = \"margin:auto\"/>\n",
    "\n",
    "To fill in deadlines for additional regions, substitute a different region for `New England` in the code from before.\n",
    "\n",
    "```\n",
    "ALTER TABLE meat_poultry_egg_establishments\n",
    "ADD COLUMN inspection_deadline\n",
    "    timestamp with time zone;\n",
    "\n",
    "UPDATE meat_poultry_egg_establishments\n",
    "    AS establishments\n",
    "SET inspection_deadline = '2022-12-01 00:00 EST'\n",
    "WHERE EXISTS (\n",
    "    SELECT state_regions.region\n",
    "    FROM state_regions\n",
    "    WHERE establishments.st = state_regions.st\n",
    "      AND state_regions.region = 'DifferentRegion'\n",
    ");\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a85d4da-a2ab-4f30-8c10-29a76e33e4db",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0423f96-a21b-4f02-bc5c-c41917d72d26",
   "metadata": {},
   "source": [
    "# Deleting Unneeded Data\n",
    "\n",
    "The most irrevocable way to modify data is to remove it entirely. SQL includes options to remove rows & columns along with options to delete an entire table or database. We want to perform these operations with caution, removing only data or tables we don't need. Without a backup, our data is gone for good.\n",
    "\n",
    "## Deleting Rows from a Table\n",
    "\n",
    "To remove rows from a table, we can use either `DELETE FROM` or `TRUNCATE` which are part of the ANSI SQL standard. Each offers options that are useful depending on our goals.\n",
    "\n",
    "Using `DELETE FROM`, we can remove all rows from a table, or we can add a `WHERE` clause to delete only the portion that matches an expression we supply. To delete all rows from a table, use the following syntax:\n",
    "\n",
    "```\n",
    "DELETE FROM table_name;\n",
    "```\n",
    "\n",
    "To remove only selected rows, add a `WHERE` clause along with the matching value or pattern to specify which ones you want to delete:\n",
    "\n",
    "```\n",
    "DELETE FROM table_name WHERE expression;\n",
    "```\n",
    "\n",
    "For example, to exclude US territories from our processors table, we can remove the companies in those locations using the code below.\n",
    "\n",
    "```\n",
    "DELETE FROM meat_poultry_egg_establishments\n",
    "WHERE st IN ('AS', 'GU', 'MP', 'PR', 'VI');\n",
    "```\n",
    "\n",
    "PostgreSQL should return the message `DELETE 105`. This means the 105 rows where the `st` column held any of the codes designating a territory you supplied via the `IN` keyword have been removed from the table.\n",
    "\n",
    "<img src = \"Deleting Rows Matching an Expression.png\" width = \"600\" style = \"margin:auto\"/>\n",
    "\n",
    "With large tables, using `DELETE FROM` to remove all rows can be inefficient because it scans the entire table as part of the process. In that case, you can use `TRUNCATE`, which skips the scan. To empty the table using `TRUNCATE`, use the following syntax:\n",
    "\n",
    "```\n",
    "TRUNCATE table_name;\n",
    "```\n",
    "\n",
    "A handy feature of `TRUNCATE` is the ability to reset an `IDENTITY` sequence, such as one you may have created to serve as a surrogate primary key, as part of the operation. To do that, add the `RESTART IDENTITY` keywords to the statement:\n",
    "\n",
    "```\n",
    "TRUNCATE table_name RESTART IDENTITY;\n",
    "```\n",
    "\n",
    "We'll skip truncating any tables for now.\n",
    "\n",
    "## Deleting a Column from a Table\n",
    "\n",
    "Earlier, we created a backup `zip` column called `zip_copy`. Now that we've finished working on fixing the issues in `zip`, we no longer need `zip_copy`. We can remove the backup column, including all the data within the column, from the table using the `DROP COLUMN` keywords in the `ALTER TABLE` statement.\n",
    "\n",
    "The syntax for removing a column is similar to other `ALTER TABLE` statements.\n",
    "\n",
    "```\n",
    "ALTER TABLE table_name\n",
    "DROP COLUMN column_name;\n",
    "```\n",
    "\n",
    "The below code removes the `zip_copy` column:\n",
    "\n",
    "```\n",
    "ALTER TABLE meat_poultry_egg_establishments\n",
    "DROP COLUMN zip_copy;\n",
    "```\n",
    "\n",
    "PostgreSQL returns the message `ALTER TABLE`, & the `zip_copy` column should be deleted. The database doesn't actually rewrite the table to remove the column; it just marks the column as deleted in its internal catalog & no longer shows it or adds data to it when new rows are added.\n",
    "\n",
    "<img src = \"Removing a Column From a Table Using DROP.png\" width = \"600\" style = \"margin:auto\"/>\n",
    "\n",
    "## Deleting a Table from a Database\n",
    "\n",
    "The `DROP TABLE` statement is a standard ANSI SQL feature that deletes a table from the database. This statement might come in handy if, for example, we have a collection of backups, or *working tables* that have outlived their usefulness. It's also useful when we need to change the structure of a table significantly; in that case, rather than using too many `ALTER TABLE` statements, we can just remove the table & create a fresh one by running a new `CREATE TABLE` statement & re-importing the data.\n",
    "\n",
    "The syntax for the `DROP TABLE` command is simple:\n",
    "\n",
    "```\n",
    "DROP TABLE table_name;\n",
    "```\n",
    "\n",
    "For example, we can delete the backup version of the `meat_poultry_egg_establishments` table.\n",
    "\n",
    "```\n",
    "DROP TABLE meat_poultry_egg_establishments_backup;\n",
    "```\n",
    "\n",
    "PostgreSQL should respond with the message `DROP TABLE` to indicate the table has been removed.\n",
    "\n",
    "<img src = \"Removing a Table From a Database Using DROP.png\" width = \"600\" style = \"margin:auto\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafd724a-7dfd-4495-93b5-5f6340a2cadd",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282f7e86-17d1-443d-bd88-629592fc7f06",
   "metadata": {},
   "source": [
    "# Using Transaction so Save or Revert Changes\n",
    "\n",
    "So far, our alterations have been final. That is, after we run a `DELETE` or `UPDATE` query (or any other query that alters our data or database structure), the only way to undo the change is to restore from a backup. However, there is a way to check our changes before finalising them & cancel the change if it's not what we intended. We do this by enclosing the SQL statement within a *transaction*, which includes keywords that allow us to commit our changes if they are successful or roll them back if not. We define a transaction using the following keywords at the beginning & end of the query:\n",
    "\n",
    "**START TRANSACTION** sinals the start of the transaction block. In PostgreSQL, you can also use the non-ANSI SQL `BEGIN` keyword.\n",
    "\n",
    "**COMMIT** signals the end of the block & saves all changes.\n",
    "\n",
    "**ROLLBACK** signals the end of the block & reverts all changes.\n",
    "\n",
    "You can include multiple statements between `BEGIN` & `COMMIT` to define a sequence of operations that perform one unit of work in a database. An example is when you buy concert tickets, which might involve two steps: charging your credit card & reserving your seats so someone else can't buy them. A database programmer would want either both steps in the transaction to happen (say, when your card charge goes through) or neither to happen (if you cancel at checkout). Defining both steps as one transaction -- also called a *transaction block* -- keeps them as a unit; if one step is canceled or throws an error, the other get cancelled too.\n",
    "\n",
    "We can use a transaction block to review changes a query makes & then decide whether to keep or discard them. In our table, let's say we're cleaning dirty data related to the company AGRO Merchants Oakland LLC. The table has three rows listing the company, but one row has an extra comma in the name:\n",
    "\n",
    "<img src = \"Demonstrating a Transaction Block 1.png\" width = \"600\" style = \"margin:auto\"/>\n",
    "\n",
    "We want that name to be consistent, so we'll remove the comma from the third row using an `UPDATE` query. But this time, we'll check the result of our update before we make it final (we'll purposely make a mistake we want to discard).\n",
    "\n",
    "```\n",
    "START TRANSACTION;\n",
    "\n",
    "UPDATE meat_poultry_egg_establishsments\n",
    "SET company = 'AGRO Merchantss Oakland LLC'\n",
    "WHERE company = 'AGRO Merchants Oakland, LLC';\n",
    "\n",
    "SELECT company\n",
    "FROM meat_poultry_egg_establishments\n",
    "WHERE company LIKE 'AGRO%'\n",
    "ORDER BY company;\n",
    "\n",
    "ROLLBACK;\n",
    "```\n",
    "\n",
    "Beginning with `START TRANSACTION`, we'll run each statement separately. The database responds with the message `START TRANSACTION`, letting us know that any succeeding changes we make to the data will not be made permanent unless we issue a `COMMIT` command. Next, we run the `UPDATE` statement, which changes the company name in the row where it has an extra comma. I intentionally added an extra `s` in the name used in the `SET` clause to introduce a mistake.\n",
    "\n",
    "When we view the names of companies starting with the letters `AGRO` using the `SELECT` statement, we see that, oops, one company name is misspelled now.\n",
    "\n",
    "<img src = \"Demonstrating a Transaction Block 2.png\" width = \"600\" style = \"margin:auto\"/>\n",
    "\n",
    "Instead of rerunning the `UPDATE` statement to fix the typo, we can simply discard the change by running the `ROLLBACK` command. When we rerun the `SELECT` statement to view the company names, we're back to where we started:\n",
    "\n",
    "<img src = \"Demonstrating a Transaction Block 1.png\" width = \"600\" style = \"margin:auto\"/>\n",
    "\n",
    "From here, you can correct your `UPDATE` statement by removing the extra `s` & rerun it, beginning with the `START TRANSACTION` statement again. If you're happy with the changes, run `COMMIT` to make them permanent.\n",
    "\n",
    "Transaction blocks are often used for more complex situations rather than checking simple changes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5180c1-6e9c-46f1-9eeb-1476c5ba89e4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13a9d9b-b440-481a-80eb-29094ff89bc3",
   "metadata": {},
   "source": [
    "# Improving Performance When Updating Large Tables\n",
    "\n",
    "With PostgreSQL, adding a column to a table & filling it with values can quickly inflate the table's size because the database creates a new version of the existing row each time a value is updated, but it doesn't delete the old row version. That essentially doubles the table's size. For small datasets, the increase is negligible, but for tables with hundreds of thousands or millions of rows, the time required to update rows & the resulting extra disk usage can be substantial.\n",
    "\n",
    "Instead of adding a column & filling it with values, we can save disk space by copying the entire table & adding a populated column during the operation. Then, we rename the tables so the copy replaces the original, & the original becomes a backup. Thus we have a fresh table without the added old rows.\n",
    "\n",
    "The below code shows how to copy `meat_poultry_egg_establishments` into a new table while adding a populated column. To do this, if you didn't already drop the `meat_poultry_egg_establishments_backup` table, go ahead & drop it. Then run a `CREATE TABLE` statement.\n",
    "\n",
    "```\n",
    "CREATE TABLE meat_poultry_egg_establishments_backup\n",
    "AS (SELECT *,\n",
    "           '2023-02-14 00:00 EST'::timestamp with time zone\n",
    "               AS reviewed_date\n",
    "    FROM meat_poultry_egg_establishments);\n",
    "```\n",
    "\n",
    "The query is a modified version of the backup script. In addition to selecting all the columns using the asterisk wildcard, we also add a column called `reviewed_date` by providing a value cast as a `timestamp` data type & the `AS` keyword. That syntax adds & fills `reviewed_date`, which we might use to track the last time we checked the status of each plant.\n",
    "\n",
    "Then, we use the below code to swap table names.\n",
    "\n",
    "```\n",
    "ALTER TABLE meat_poultry_egg_establishments\n",
    "RENAME TO meat_poultry_egg_establishments_temp;\n",
    "\n",
    "ALTER TABLE meat_poultry_egg_establishments_backup\n",
    "RENAME TO meat_poultry_egg_establishments;\n",
    "\n",
    "ALTER TABLE meat_poultry_egg_establishments_temp\n",
    "RENAME TO meat_poultry_egg_establishments_backup;\n",
    "```\n",
    "\n",
    "Here, we use `ALTER TABLE` with a `RENAME TO` clause to change a table name. The first statement changes the original table name to one that ends with `_temp`. The second statement renames the copy we made with the original name of the table. Finally, we rename the table that ends with `_temp` to the ending `_backup`. The original table is now called `meat_poultry_eggs_establishments_backup`, & the copy with the added column is called `meat_poultry_egg_establishments`. This process avoids updating rows & thus inflating the table.\n",
    "\n",
    "<img src = \"Swapping Table Names Using ALTER TABLE.png\" width = \"600\" style = \"margin:auto\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1621d60-1c2f-4dce-9458-ef0765230333",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af3ebed-84c4-4cb0-9e33-3d61587e61bd",
   "metadata": {},
   "source": [
    "# Wrapping Up\n",
    "\n",
    "Gleaning useful information from data sometimes requires modifying the data to remove inconsistencies, fix errors, & make it more suitable for supporting an accurate analysis. In a perfect world, datasets would arrive with everything clean & complete. But such a perfect world doesn't exist, so the ability to alter, update, & delete data is indispensable.\n",
    "\n",
    "Be sure to back up your tables before you start making changes. Make copies of your columns too, for an extra level of protection."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
