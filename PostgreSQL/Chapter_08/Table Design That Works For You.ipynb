{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "916c0dd8-727d-4638-9604-16b320937c4b",
   "metadata": {},
   "source": [
    "# Table Design That Works For You\n",
    "\n",
    "Obsession with order & detail can be a good thing. When you're running out the door, it's reassuring to see your keys hanging on the hook where you *always* leave them. The same is true for database design. When you need to excavate a nugget of information from dozens of tables & millions of rows, you appreciate a dose of that same detail obsession. With data organised & finely tuned, smartly named set of tables, the analysis experience becomes much more managable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed28dcae-0c7e-4e02-9c92-96c62471e1b7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c9d159-6266-4650-a1cf-6c7e9105072b",
   "metadata": {},
   "source": [
    "# Following Naming Conventions\n",
    "\n",
    "Programming languages tend to have their own style patterns & even various factions of SQL coders prefer certain conventions when naming tables, columns, & other objects (called *identifiers*). Some like *camel case* as in `berrySmoothie`, where words are strung together & the first letter of each word is capitalised except for the first word. *Pascal case*, as in `BerrySmoothie`, follows a similar pattern but capitalises the first letter too. With *snake case*, as in `berry_smoothie`, all the words are lowercase & separated by underscores.\n",
    "\n",
    "Mixing styles or following none generally leads to a mess. For example, imagine connecting to a database & finding the following collection of tables:\n",
    "\n",
    "```\n",
    "Customers\n",
    "customers\n",
    "custBackup\n",
    "customer_analysis\n",
    "customer_test2\n",
    "customer_testMarch2012\n",
    "customer_analysis\n",
    "```\n",
    "You would have questions. For one, which table actually holds the current data on customers? A disorganised naming scheme -- & a general lack of tidiness -- makes it hard for others to dive into your data & makes it challenging for you to pick up where you left off. \n",
    "\n",
    "## Quoting Identifiers Enables Mixed Case\n",
    "\n",
    "Regardless of any capitalisation you supply, PostgreSQL treats identifiers as lowercase unless you place double quotes around the identifier. Consider the two `CREATE TABLE` statements for PostgreSQL:\n",
    "\n",
    "```\n",
    "CREATE TABLE customers (\n",
    "    customer_id text,\n",
    "    ...\n",
    ");\n",
    "\n",
    "CREATE TABLE Customers (\n",
    "    customer_id text,\n",
    "    ...\n",
    ");\n",
    "```\n",
    "\n",
    "When you execute these statemenets in order, the first command creates a table called `customers`. The second statement, rather than creating a separate table called `Customers`, will throw an error: `relation \"customers\" already exists`. Because you didn't quote the identifier, PostgreSQL treats `customers` & `Customers` as the same identifier, disregarding the case. To preserve the uppercase letter & create a separate table named `Customers`, we must surround the identifer with quotes, like so:\n",
    "\n",
    "```\n",
    "CREATE TABLE \"Customers\" (\n",
    "    customer_id serial,\n",
    "    ...\n",
    ");\n",
    "```\n",
    "\n",
    "However, because this requires quotes to query `Customers` rather than `customers`, we have to quote its name in the `SELECT` statement as well:\n",
    "\n",
    "```\n",
    "SELECT * FROM \"Customers\";\n",
    "```\n",
    "\n",
    "That can be a chore to remember & make users vulnerable to a mix-up. Makes sure your tables have names that are clear & distinct from other tables in the database.\n",
    "\n",
    "## Pitfalls with Quoting Identifiers\n",
    "\n",
    "Quoting identifiers also allows us to use characters not otherwise allowed, including spaces. That may appeal to some folks, but there are negatives. You may want to throw quotes around `\"trees planted\"` as a column name in a reforestation database, but then all users will have to provide quotes on every reference to that column. Omit the quotes in a query, & the database will respond with an error, identifying `trees` & `planted` as separate columns & responding that `trees` does not exist. The more readable & reliable option is to use snake case, as in `trees_planted`.\n",
    "\n",
    "Quotes also let us use SQL *reserved keywords*, which are words that have special meaning in SQL. We've already encounter several, such as `TABLE`, `WHERE`, or `SELECT`. Most database developers frown on using reserved keywords as identifiers. At a minimum, it's confusing & at worst, neglecting or forgetting to quote that keyword later may result in an error because the database will interpret the word as a command instead of an identifier.\n",
    "\n",
    "## Guidelines for Naming Identifiers\n",
    "\n",
    "Given the extra burden of quoting & its potential problems, it's best to keep your identifer names simple, unquoted, & consistent. Here are some recommendations:\n",
    "\n",
    "1. **Use snake case.** Snake case is reliable, as shown in the earlier `trees_planted` example.\n",
    "2. **Make names easy to understand & avoid cryptic abbreviations.** If you're building a database related to travel, `arrival_time` is a clearer column name than `arv_tm`.\n",
    "3. **For table names, use plurals.** Tables hold rows, & each row represents one instances of an entity. So, use plural names for tables, such as `teachers`, `vehicles`, & `departments`.\n",
    "4. **Mind the length.** If you're writing code that may get reused in another database system, lean toward shorter identifier names.\n",
    "5. **When making copies of tables, use names that will help you manage them later.** One method is to append a `_YYYY_MM_DD` date to the table name when you create a copy, such as `vehicle_parts_2024_11_13`. An additional benefit is that the table names will sort in date order."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3513551-31d2-488b-a5e2-188ec71b62b9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfa65cf-9220-4db3-945d-709698d59a3c",
   "metadata": {},
   "source": [
    "# Controlling Column Names with Constraints\n",
    "\n",
    "You can maintain further control over the data a column will accept by using certain constraints. A column's data type broadly defines the kind of data it will accept: integers versus characters, for example. Additional constraints let us further specify acceptable values based on rules & logical tests. With constraints, we can avoid the \"garbage in, garbage out\" phenomenon, which happens when poor-quality data results in inaccurate or incomplete analysis. Well-designed constraints help maintain the quality of the data & ensure the integrity of the relationships among tables.\n",
    "\n",
    "Previously, we learned about *primary* & *foreign keys*, which are two of the most commonly used contraints. SQL also has the following constraint types:\n",
    "\n",
    "* **CHECK:** allows only those rows where a supplied Boolean expression evaluates to `true`\n",
    "* **UNIQUE:** ensures the values in a column or group of columns are unique in each row in the table\n",
    "* **NOT NULL:** prevents `NULL` values in a column\n",
    "\n",
    "We can add constraints in two ways: as a *column constraint* or as a *table constraint*. A column contraint applies only to that column. We declare it with the column name & data type in the `CREATE TABLE` statement, & it gets checked whenever a change is made to the column. With a table constraint, we can supply criteria that apply to one or more columns. We declare it in the `CREATE TABLE` statement immediately after defining all the table columns, & it gets checked whenever a change is made to a row in the table.\n",
    "\n",
    "## Primary Keys: Natural vs Surrogate\n",
    "\n",
    "A *primary key* is a column or collection of columns whose values uniquely identify each row in a table. A primary key is a constraint, & it imposes two rules on the column or columns that make up the key:\n",
    "\n",
    "1. Values must be unique for each row.\n",
    "2. No column can have missing values.\n",
    "\n",
    "In a table of products stored in a warehouse, the primary key could be a column of unique product codes. In the simple primary key examples in previous lessons, our tables had a primary key made from a single ID column with an integer inserted by us, the user. Often, the data will suggest the best path & help us decide whether to use a *natural key* or a *surrogate key* as the primary key.\n",
    "\n",
    "### Using Existing Columns for Natural Keys\n",
    "\n",
    "A natural key uses one or more of the table's existing columns that meet the criteria for a primary key: unique for every row & never empty. Values in the columns can change as long as the new value doesn't cause a violation of the constraint.\n",
    "\n",
    "A natural key might be a driver's license identification number issued by a local DMV. Within government jurisdiction, such as a state in the United States, we'd reasonably expect that all drivers would receive a unique ID on their licenses, which we could store as `driver_id`. However, if we were compiling a national driver's license database, we might not be able to make that assumption: several states could independently issue the same ID code. In that case, the `driver_id` column may not have unique values & cannot be used as the natural key. As a solution, we could create a *composite primary key* by combining `driver_id` with a column holding the state name, which would give us a unique combination for each row. For example, both rows in this table have a unique combination of the `driver_id` & `st` columns:\n",
    "\n",
    "|driver_id|st|first_name|last_name|\n",
    "|:---|:---|:---|:---|\n",
    "|10302019|NY|Patrick|Corbin|\n",
    "|10302019|FL|Howard|Kendrick|\n",
    "\n",
    "We'll visit both approaches in this lesson, & as we work with data, we'll keep an eye out for values suitable for natural keys. A part number, a serial number, or a book's ISBN are all good examples.\n",
    "\n",
    "### Introducing Columns for Surrogate Keys\n",
    "\n",
    "A *surrogate* key is a single column that you fill with artificial values; we might use it when a table doesn't have data that supports creating a natural primary key. The surrogate key might be sequential number autogenerated by the database. We've already done this with the serial data type & the `IDENTITY` syntax. A table using an autogenerate integer for a surrogate key might look like this: \n",
    "\n",
    "|id|first_name|last_name|\n",
    "|:---|:---|:---|\n",
    "|1|Patrick|Corbin|\n",
    "|2|Howard|Kendrick|\n",
    "|3|David|Martinez|\n",
    "\n",
    "Some developers like to use a *universally unique identifier* (UUID), which is a code comprised of 32 hexadecimal digits in groups separated by hyphens. Often UUIDs are used to identify computer hardware or software & look like the following:\n",
    "\n",
    "```\n",
    "2911d8a8-6dea-4a46-af23-d64175a08237\n",
    "```\n",
    "\n",
    "PostgreSQL offers a UUID data type as well as two modules that generate UUIDs: `uuid-ossp` & `pgcrypto`. The [PostgreSQL documentation](https://www.postgresql.org/docs/current/datatype-uuid.html) is a good starting point for diving deeper.\n",
    "\n",
    "### Evaluating the Pros & Cons of Key Types\n",
    "\n",
    "There are well-reasoned arguments for using either type of primary key, but both have drawbacks. Points to consider about natural keys include the following:\n",
    "\n",
    "1. The data already exists in the table, so you don't need to add a column to create a key.\n",
    "2. Because the natural key data has meaning, it can reduce the need to join tables when querying.\n",
    "3. If you data changes in a way that violates the requirements for a key -- sudden appearance of duplicate values, for instance -- you'll be forced to change the setup of the table.\n",
    "\n",
    "Here are points to consider about surrogate keys:\n",
    "\n",
    "1. Because a surrogate key doesn't have any meaning in itself & its values are independent of the data in the table, you're not limited by the key structure if your data changes later.\n",
    "2. Key values are guaranteed to be unique.\n",
    "3. Adding a column for a surrogate key requires more space.\n",
    "\n",
    "In a perfect world, a table should have one or more columns that can serve as a natural key, such as a unique product code in a table of products. But real-world limitations arise all the time. In a table of employees, it might be difficult to find any single column, or even multiple columns, that would be unique on a row-by-row basis to serve as a primary key. In such cases where you can't reconsider the table structure, you may need to use a surrogate key.\n",
    "\n",
    "### Creating a Single-Column Primary Key\n",
    "\n",
    "Let's work through several primary key examples. Previously, we created primary keys on the `district_2020` & `district_2035` tables to try `JOIN` types. In fact, these were surrogate keys: in both tables, we created columns called `id` to use as the key & used the keywords `CONSTRAINT key_name PRIMARY KEY` to declare them as primary keys.\n",
    "\n",
    "There are two ways to declare constraints: as a column constraint or as a table constraint. In the below code, we try both methods, declaring a primary key on a table similar to the driver's license example mentioned earlier. Because we expect the driver's license IDs to always to be unique, we'll use that column as a natural key.\n",
    "\n",
    "```\n",
    "CREATE TABLE natural_key_example (\n",
    "    license_id text CONSTRAINT license_key PRIMARY KEY,\n",
    "    first_name text,\n",
    "    last_name text\n",
    ");\n",
    "\n",
    "DROP TABLE natural_key_example;\n",
    "\n",
    "CREATE TABLE natural_key_example (\n",
    "    license_id text,\n",
    "    first_name text,\n",
    "    last_name text,\n",
    "    CONSTRAINT license_key PRIMARY KEY (license_id)\n",
    ");\n",
    "```\n",
    "\n",
    "We first create a table called `natural_key_example` & use the column constraint syntax `CONSTRAINT` to declare `license_id` as the primary key, followed by a name for the constraint & the keywords `PRIMARY KEY`. This syntax makes it easy to understand at a glance which column is designated as the primary key. Note that you can omit the `CONSTRAINT` keyword & name for the key & simply use `PRIMARY KEY`:\n",
    "\n",
    "```\n",
    "license_id text PRIMARY KEY\n",
    "```\n",
    "\n",
    "In that case, PostgreSQL will name the primary key on its own, using the convention of the table name followed by `_pkey`.\n",
    "\n",
    "Next, we delete the table from the database with `DROP TABLE` to prepare for the table constraint example.\n",
    "\n",
    "To add a table constraint, we declare the `CONSTRAINT` after listing all the columns, with the column we want to use as the key in parentheses. (Again, we can omit the `CONSTRAINT` keyword & key name.) In this example, we end up with the same `license_id` column for the primary key. We must use the table constraint syntax when we want to create a primary key using more than one column; in that case, we would list the columns in the parentheses, separated by commas.\n",
    "\n",
    "Let's look at how the qualities of a primary key -- unique for every row & no `NULL` values -- protect us from harming our data's integrity. The below code has two `INSERT` statements.\n",
    "\n",
    "```\n",
    "INSERT INTO natural_key_example (\n",
    "    license_id, first_name, last_name\n",
    ")\n",
    "VALUES ('T229901', 'Gem', 'Godfrey');\n",
    "\n",
    "INSERT INTO natural_key_example (\n",
    "    license_id, first_name, last_name\n",
    ")\n",
    "VALUES ('T229901', 'John', 'Mitchell');\n",
    "```\n",
    "\n",
    "When you execute the first `INSERT` statement on its own, the server loads a row into the `natural_key_example` table without any issue. When you attempt to execute the second, the server replies with an error:\n",
    "\n",
    "<img src = \"Primary Key Violation.png\" width = \"600\" style = \"margin:auto\"/>\n",
    "\n",
    "Before adding the row, the server checked whether a `license_id` of `T229901` was already present in the table. Because it was & because a primary key by definition must be unique for each row, the server rejected the operation. The rules of the fictional DMV state that no two drivers can have the same license ID, so checking for & rejecting duplicate data is one way for the database to enforce that rule.\n",
    "\n",
    "### Creating a Composite Primary Key\n",
    "\n",
    "If a single column doesn't meet the requirements for a primary key, we can create a *composite primary key*. \n",
    "\n",
    "We'll make a table that tracks student school attendance. The combination of `student_id` & `school_day` columns gives us a unique value for each row, which records whether a student was in school on that day in a column called `present`. To create a composite primary key, we must declare it using the table constraint syntax.\n",
    "\n",
    "```\n",
    "CREATE TABLE natural_key_composite_example (\n",
    "    student_id text,\n",
    "    school_day date,\n",
    "    present boolean,\n",
    "    CONSTRAINT student_key PRIMARY KEY (student_id, school_day)\n",
    ");\n",
    "```\n",
    "\n",
    "Here, we pass two (or more) columns as arguments rather than one. We'll simulate a key violation by attempting to insert a row where the combination of values in the two key columns -- `student_id` & `school_day` -- is not unique to the table. Run the `INSERT` statements below one at a time.\n",
    "\n",
    "```\n",
    "INSERT INTO natural_key_composite_example (\n",
    "    student_id, school_day, present\n",
    ")\n",
    "VALUES (775, '2022-01-22', 'Y');\n",
    "\n",
    "INSERT INTO natural_key_composite_example (\n",
    "    student_id, school_day, present\n",
    ")\n",
    "VALUES (775, '2022-01-23', 'Y');\n",
    "\n",
    "INSERT INTO natural_key_composite_example (\n",
    "    student_id, school_day, present\n",
    ")\n",
    "VALUES (775, '2022-01-23', 'N');\n",
    "```\n",
    "\n",
    "The first two `INSERT` statements execute fine because there's no duplication of values in the combination of key columns. But the third statement causes an error because the `student_id` & `school_day` values it contains match a combination that already exists in the table:\n",
    "\n",
    "<img src = \"Composite Primary Key Violation.png\" width = \"600\" style = \"margin:auto\"/>\n",
    "\n",
    "You can create composite keys with more than two columns. The limit to the number of columns you can use depends on your database.\n",
    "\n",
    "### Creating an Auto-Incrementing Surrogate Key\n",
    "\n",
    "As we've learned previously, there are two ways to have a PostgreSQL database add an automatically increasing unique value to a column. The first is to set the column to one of the PostgreSQL-specific serial data types: `smallserial`, `serial`, & `bigserial`. The second is to use the `IDENTITY` syntax; because it is part of the ANSI SQL standard -- we'll employ this for our examples.\n",
    "\n",
    "Use `IDENTITY` with one of the integer types `smallint`, `integer`, & `bigint`. For a primary key, it may be tempting to try to save disk space by using `integer`, which handles numbers as large as 2,147,483,647. But many a database developer has received a late-night call from a user frantic to know why an application is broken, only to discover that the database is trying to generate a number one greater than the data type's maximum. So, if it's remotely possible that your table will grow past 2.147 billion rows, it's wise to use `bigint`, which accepts numbers as high as 9.2 quintillion. You can set it & forget it.\n",
    "\n",
    "```\n",
    "CREATE TABLE surrogate_key_example (\n",
    "    order_number bigint GENERATED ALWAYS AS IDENTITY,\n",
    "    product_name text,\n",
    "    order_time timestamp with time zone,\n",
    "    CONSTRAINT order_number_key PRIMARY KEY (order_number)\n",
    ");\n",
    "\n",
    "INSERT INTO surrogate_key_example (\n",
    "    product_name, order_time\n",
    ")\n",
    "VALUES ('Beachball Polish', '2020-03-15 09:21-07'),\n",
    "       ('Wrinkle De-Atomiser', '2017-05-22 14:00-07'),\n",
    "       ('Flux Capacitor', '1985-10-26 01:18:00-07');\n",
    "\n",
    "SELECT * FROM surrogate_key_example;\n",
    "```\n",
    "\n",
    "The code above shows how to declare an auto-incrementing `bigint` column called `order_number` using the `IDENTITY` syntax & then set the column as the primary key. When you insert data into the table, you omit `order_number` from the list of columns & values. The database will create a new value for that column as each row is inserted, & that value will be one greater than the largest already created for the column.\n",
    "\n",
    "<img src = \"bigint Column as Surrogate Key Using IDENTITY.png\" width = \"600\" style = \"margin:auto\"/>\n",
    "\n",
    "We see these sorts of auto-incrementing order numbers reflected in the receipts for the purchases we make every day. \n",
    "\n",
    "A few details worth noting: if you delete a row, the database won't fill the gap in the `order_number` sequence, nor will it change any of the existing values in that column. It will generally add one to the largest existing value in the sequence (though there are exceptions related to operations, including restoring a database from a backup). Also, we used the syntax `GENERATED ALWAYS AS IDENTITY`. This prevents a user from inserting a value in `order_number` without manually overriding this setting. Generally, you want to prevent such meddling to avoid problems. Let's say a user were to manually insert a value of `4` into the `order_number` column of your existing `surrogate_key_example` table. That manual insert will not increment the `IDENTITY` sequence for the `order_number` column; that occurs only when the database generates a new value. Thus, on the next row insert, the database also would try to insert a `4`, as that's the next number in the sequence. The result will be an error, because a duplicate value violates the primary key constraint.\n",
    "\n",
    "You can, however, allow manual insertions by restarting the `IDENTITY` sequence. You might allow this in case you need to insert a row that was mistakenly deleted. The below code shows how to add a row to the table that has an `order_number` of `4`, which is the next value in the sequence.\n",
    "\n",
    "```\n",
    "INSERT INTO surrogate_key_example\n",
    "OVERRIDING SYSTEM VALUE\n",
    "VALUES (4, 'Chicken Coop', '2021-09-03 10:33-06');\n",
    "\n",
    "ALTER TABLE surrogate_key_example ALTER COLUMN order_number\n",
    "RESTART WITH 5;\n",
    "\n",
    "INSERT INTO surrogate_key_example (\n",
    "    product_name, order_time\n",
    ")\n",
    "VALUES ('Aloe Plant', '2020-03-15 10:09-07');\n",
    "```\n",
    "\n",
    "You start with an `INSERT` statement that includes the keywords `OVERRIDING SYSTEM VALUE`. Next, we include the `VALUES` clause & specify the integer `4` for the first column, `order_number`, in the `VALUES` list, which overrides the `IDENTITY` restriction. We're using `4`, but we could choose any number that's not already present in the column.\n",
    "\n",
    "After the insert, you need to reset the `IDENTITY` sequence so that it begins at a number larger than `4` you just inserted. To do this, use an `ALTER TABLE ... ALTER COLUMN` statement that includes the keywords `RESTART WITH 5`. An `ALTER TABLE` modifies tables & columns in various ways. Here, we use it to change the beginning number of the `IDENTITY` sequence; so, when the next row gets added to the table, the value for `order_number` will be `5`. Finally, insert a new row & omit a value for the `order_number`.\n",
    "\n",
    "If you select all rows again for the `surrogate_key_example` table, we'll see that the `order_number` column populated as intended:\n",
    "\n",
    "<img src = \"Restarting an IDENTITY Sequence.png\" width = \"600\" style = \"margin:auto\"/>\n",
    "\n",
    "## Foreign Keys\n",
    "\n",
    "We use *foreign keys* to establish relationships between tables. A foreign key is one or more columns whose values match those in another table's primary key or other unique key of the table it references. If not, the value is rejected. With this constraint, SQL enforces *referential integrity* -- ensuring that data in related tables doesn't end up unrelated, or orphaned.\n",
    "\n",
    "We won't end up with rows in one table that have no relation to rows in the other table we can join them to.\n",
    "\n",
    "The below code shows two tables from a hypothetical database tracking motor vehicle activity.\n",
    "\n",
    "```\n",
    "CREATE TABLE licenses (\n",
    "    license_id text,\n",
    "    first_name text,\n",
    "    last_name text,\n",
    "    CONSTRAINT licenses_key PRIMARY KEY (license_id)\n",
    ");\n",
    "\n",
    "CREATE TABLE registrations (\n",
    "    registration_id text,\n",
    "    registration_date timestamp with time zone,\n",
    "    license_id text REFERENCES licenses (license_id),\n",
    "    CONSTRAINT registration_key PRIMARY KEY (registriation_id,\n",
    "        license_id)\n",
    ");\n",
    "\n",
    "INSERT INTO licenses (\n",
    "    license_id, first_name, last_name\n",
    ")\n",
    "VALUES ('T229901', 'Steve', 'Rothery');\n",
    "\n",
    "INSERT INTO registrations (\n",
    "    registration_id, registration_date, license_id\n",
    ")\n",
    "VALUES ('A203391', '2022-03-17', 'T229901');\n",
    "\n",
    "INSERT INTO registrations (\n",
    "    registration_id, registration_date, license_id\n",
    ")\n",
    "VALUES ('A75772', '2022-03-17', 'T000001');\n",
    "```\n",
    "\n",
    "The first table, `licenses`, uses a driver's unique `license_id` as a natural primary key. The second table, `registrations`, is for tracking vehicle registrations. A single license ID might be connected to multiple vehicle registrations, because each licensed driver can register multiple vehicles -- this is called a *one-to-many relationship*.\n",
    "\n",
    "Here's how that relationship is expressed via SQL: in the `registrations` table, we designate the column `license_id` as a foreign key by adding the `REFERENCES` keyword, followed by the table name & column for it to reference.\n",
    "\n",
    "Now, when we insert a row into `registrations`, the database will test whether the value inserted into `license_id` already exists in the `license_id` primary key column of the `licenses` table. If it doesn't, the database returns an error, which is important. If any rows in `registrations` didn't correspond to a row in `licenses`, we'd have no way to write a query to find the person who registered the vehicle.\n",
    "\n",
    "To see this constraint in action, create the two tables & execute the `INSERT` statements one at a time. The first adds a row to `licenses` that includes the value `T22901` for the `license_id`. The second adds a row to `registrations` where the foreign key contains the same value. So far, so good, because the value exists in both tables. But, we encounter an error with the third insert, which tries to add a row to `registrations` with a value for `license_id` that's not in `licenses`:\n",
    "\n",
    "<img src = \"Foreign Key Example.png\" width = \"600\" style = \"margin:auto\"/>\n",
    "\n",
    "The resulting error is actually helpful: the database is enforcing referential integrity by preventing a registration for a nonexisting license holder. But it also indicates a few practical implications. First, it affects the order in which we insert data. We cannot add data to a table that contains a foreign key before the other table referenced by the key has the related records, or we'll get an error. In this example, we'd have to create a driver's license record before inserting a related registration record (if you think about it, that's what your local DMV probably does).\n",
    "\n",
    "Second, the reverse applies when we delete data. To maintain referential integrity, the foreign key constraint prevents us from deleting a row from `licenses` before removing any related rows in `registrations`, because doing so would leave an orphaned record. We would have to delete the related row in `registrations` first & then delete the row in `licenses`. However, ANSI SQL standard provides a way to handle this order of operations automatically using the `ON DELETE CASCADE` keywords.\n",
    "\n",
    "## How to Automatically Delete Related Records with CASCADE\n",
    "\n",
    "To delete a row in `licenses` & have that action automatically delete any related rows in registrations, we can specify that behaviour by adding `ON DELETE CASCADE` when defining the foreign key constraint.\n",
    "\n",
    "Here's how we would modify the `CREATE TABLE` statement for `registrations`, adding the keywords at the end of the definition of the `license_id` column:\n",
    "\n",
    "```\n",
    "CREATE TABLE registriations (\n",
    "    registration_id text,\n",
    "    registration_date date,\n",
    "    license_id text REFERENCES licenses (license_id)\n",
    "        ON DELETE CASCADE,\n",
    "    CONSTRAINT registration_key PRIMARY KEY (\n",
    "        registration_id, license_id\n",
    "    )\n",
    ")\n",
    "```\n",
    "\n",
    "Deleting a row in `licenses` should also delete all related rows in `registrations`. This allows us to delete a driver's license without first having to manually remove any registrations linked to it. It also maintains data integrity by ensuring deleting a license doesn't leave orphaned rows in `registrations`.\n",
    "\n",
    "## The CHECK Constraint\n",
    "\n",
    "A check constraint evaluates whether data added to a column meets the expected criteria, which we specify with a logical test. If the criteria aren't met, the database returns an error. The `CHECK` constraint is extremely valuable because it can prevent columns from getting loaded with nonsensical data. For example, a baseball player's total number of hits shouldn't be negative, so you should limit the data to values of zero or greater. Or, in schools, `Z` isn't a valid letter grade for a course, so we might insert constraints that only accepts the values A-F.\n",
    "\n",
    "As with primary keys, we can implement a `CHECK` constraint at the column or table level. For a column constraint, declare it in the `CREATE TABLE` statement after the column name & data type: `CHECK (logical expression)`. As a table constraint, use the syntax `CONSTRAINT constraint_name CHECK (logical expression)` after all columns are defined.\n",
    "\n",
    "The below code shows a `CHECK` constraint applied on two columns in a table we might use to track the user role & salary of employees within an organisation. It uses the table constraint syntax for the primary key & the `CHECK` constraint.\n",
    "\n",
    "```\n",
    "CREATE TABLE check_constraint_example (\n",
    "    user_id bigint GENERATED ALWAYS AS IDENTITY,\n",
    "    user_role text,\n",
    "    salary numeric(10, 2),\n",
    "    CONSTRAINT user_id key PRIMARY KEY (user_id),\n",
    "    CONSTRAINT check_role_in_list CHECK (user_role IN('Admin', 'Staff')),\n",
    "    CONSTRAINT check_salary_not_below_zero CHECK (salary >= 0)\n",
    ")\n",
    "```\n",
    "\n",
    "We create the table & set the `user_id` column as an auto-incrementing surrogate primary key. The first `CHECK` tests whether values entered into the `user_role` column match one of two predefined strings, `Admin` or `Staff`, by using the SQL `IN` operator. The second `CHECK` tests whether values entered in the `salary` column are greater than or equal to 0, because a negative amount wouldn't make sense. Both tests are an example of a *Boolean expression*, a statement that evaluates as either true or false. If a value tested by the constraint evaluates as `true`, the check passes.\n",
    "\n",
    "When values are inserted or updated, the database checks them against the constraint. If the values in either column violate the constraint -- or, for that matter, if the primary key constraint is violated -- the database will reject the change.\n",
    "\n",
    "If we use the table constraint syntax, we also can combine more than one test in a single `CHECK` statement. Say, we have a table related to student achievement. We could add the following:\n",
    "\n",
    "```\n",
    "CONSTRAINT grad_check CHECK (credits >= 120 AND tuition = 'Paid')\n",
    "```\n",
    "\n",
    "Notice that we combine two logical test by enclosing them in parentheses & connecting them with `AND`. Here, both Boolean expressions must evaluate to `true` for the entire check to pass. You can also test values across columns, as in the following example where we want to make sure an item's sales price is a discount on the original, assuming we have columns for both values:\n",
    "\n",
    "```\n",
    "CONSTRAINT sale_check CHECK (sale_price < retail_price)\n",
    "```\n",
    "\n",
    "Inside the parentheses, the logical expression checks that the sale price is less than the retail price.\n",
    "\n",
    "## The UNIQUE Constraint\n",
    "\n",
    "We can also ensure that a column has a unique value in each row by using the `UNIQUE` constraint. If ensuring unique values sounds similar to the purpose of a primary key, it is. But `UNIQUE` has one important difference. In a primary key, no values can be `NULL`, but a `UNIQUE` constraint permits multiple `NULL` values in a column. This is useful in cases where we won't always have values but want to ensure that the ones we do have are unique.\n",
    "\n",
    "To show the usefulness of `UNIQUE`, look at the code below, which is a table for tracking contact info.\n",
    "\n",
    "```\n",
    "CREATE TABLE unique_constraint_example (\n",
    "    contact_id bigint GENERATED ALWAYS AS IDENTITY,\n",
    "    first_name text,\n",
    "    last_name text,\n",
    "    email text,\n",
    "    CONSTRAINT contract_id key PRIMARY KEY (contact_id),\n",
    "    CONSTRAINT email_unique UNIQUE (email)  \n",
    ");\n",
    "\n",
    "INSERT INTO unique_constraint_example (\n",
    "    first_name, last_name, email\n",
    ")\n",
    "VALUES ('Samantha', 'Lee', 'slee@example.org');\n",
    "\n",
    "INSERT INTO unique_constraint_example (\n",
    "    first_name, last_name, email\n",
    ")\n",
    "VALUES ('Betty', 'Diaz', 'bdiaz@example.org');\n",
    "\n",
    "INSERT INTO unique_constraint_example (\n",
    "    first_name, last_name, email\n",
    ")\n",
    "VALUES ('Sasha', 'Lee', 'slee@example.org');\n",
    "```\n",
    "\n",
    "In this table, `contact_id` serves as a surrogate primary key, uniquely identifying each row. But we also have an `email` column, the main point of contact with each person. We'd expect this column to contain only unique email addresses, but those addresses might change over time. So, we use `UNIQUE` to ensure that any time we add or update a contact's email, we're not providing one that already exists. If we try to insert an email that already exists, the database will return an error:\n",
    "\n",
    "<img src = \"UNIQUE Constraint Example.png\" width = \"600\" style = \"margin:auto\"/>\n",
    "\n",
    "Again, the error shows the database is working for us.\n",
    "\n",
    "## The NOT NULL Constraint\n",
    "\n",
    "Previously, we learned about `NULL`, a special SQL value that represents missing data or unknown values. We know that `NULL` is not allowed for primary key values because they need to uniquely identify each row in a table. But there may be other times when you'll want to disallow empty values in a column. For example, in a table listing each student in a school, requiring that columns containing first & last names be filled for each row makes sense. To require a value in a column, SQL provides the `NOT NULL` constraint, which simply prevents a column from accepting empty values.\n",
    "\n",
    "The below code demonstrates the `NOT NULL` syntax.\n",
    "\n",
    "```\n",
    "CREATE TABLE not_null_example (\n",
    "    student_id bigint GENERATED ALWAYS AS IDENTITY,\n",
    "    first_name text NOT NULL,\n",
    "    last_name text NOT NULL,\n",
    "    CONSTRAINT student_id_key PRIMARY KEY (student_id)\n",
    ");\n",
    "```\n",
    "\n",
    "Here, we declare `NOT NULL` for the `first_name` & `last_name` columns because it's likely we'd require those pieces of information in a table tracking student information. If we attempt an `INSERT` on the table & don't include values for those columns, the database will notify use of the violation.\n",
    "\n",
    "## How to Remove Constraints or Add Them Later\n",
    "\n",
    "You can remove a constraint or later add one to an existing table using `ALTER TABLE`, the command we used earlier to reset the `IDENTITY` sequence.\n",
    "\n",
    "To remove a primary key, foreign key, or `UNIQUE` constraint, we write an `ALTER TABLE` statement in this format:\n",
    "\n",
    "```\n",
    "ALTER TABLE table_name DROP CONSTRAINT constraint_name;\n",
    "```\n",
    "\n",
    "To drop a `NOT NULL` constraint, the statement operates on the column, so we must us the additional `ALTER COLUMN` keywords, like so:\n",
    "\n",
    "```\n",
    "ALTER TABLE table_name ALTER COLUMN column_name DROP NOT NULL;\n",
    "```\n",
    "\n",
    "Let's use these statements to modify the `not_null_example` table we just made.\n",
    "\n",
    "```\n",
    "ALTER TABLE not_null_example\n",
    "    DROP CONSTRAINT student_id_key;\n",
    "\n",
    "ALTER TABLE not_null_example\n",
    "    ADD CONSTRAINT student_id_key\n",
    "    PRIMARY KEY (student_id);\n",
    "\n",
    "ALTER TABLE not_null_example ALTER COLUMN first_name\n",
    "    DROP NOT NULL;\n",
    "\n",
    "ALTER TABLE not_null_example ALTER COLUMN first_name\n",
    "    SET NOT NULL;\n",
    "```\n",
    "\n",
    "Execute the statements one at a time. Each time, you can view the changes to the table definition in pgAdmin by clicking the table name once & then clicking the **SQL** tab above the query window.\n",
    "\n",
    "With the first `ALTER TABLE` statement, we use `DROP CONSTRAINT` to remove the primary key named `student_id_key`. We then add the primary key back using `ADD CONSTRAINT`. We'd use that same syntax to add a constraint to any existing table.\n",
    "\n",
    "In the third statement, `ALTER COLUMN` & `DROP NOT NULL` remove the `NOT NULL` constraint from the `first_name` column. Finally, `SET NOT NULL` adds the constraint."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5212a6e8-43f5-47f5-afd7-83365798ec64",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38bb19a-06df-44d9-8841-e09983a87290",
   "metadata": {},
   "source": [
    "# Speeding Up Queries with Indexes\n",
    "\n",
    "In the same way that a book's index helps us find information more quickly, we can speed up queries by adding an *index* -- a separate data structure the database manages -- to one or more columns in a table. The database uses the index as a shortcut rather than scanning each row to find data. Here, we'll offer general guidance on using indexes & a PostgreSQL-specific example that demonstrates their benefits.\n",
    "\n",
    "## B-Tree: PostgreSQL's Default Index\n",
    "\n",
    "In PostgreSQL, the default index type is the *B-tree index*. It's created automatically on the columns designated for the primary key or a `UNIQUE` constraint, & it's also the type created by default with the `CREATE INDEX` statement. B-tree, short for *balanced tree*, is so named because when you search for a value, the structure looks from the top of the tree down through branches until it locates the value. A B-tree index is useful for data that can be ordered & searched using equality & range operators, such as `<`, `<=`, `=`, `>=`, `>`, & `BETWEEN`. It also works with `LIKE` if there's no wildcard in the pattern at the beginning of the search string. An example is `WHERE chips LIKE 'Dorito%'`.\n",
    "\n",
    "PostgreSQL also supports additional index types, such as *Generalised Inverted Index* (GIN) & the *Generalised Search Tree* (GiST). For now, let's see a B-tree index speed up a simple search query. For this exercise, we'll use a large dataset comprising more than 900,000 New York City street addresses, compiled by the OpenAddresses project. The file with the data `city_of_new_york.csv`, is available along with all the resources downloaded for this course.\n",
    "\n",
    "Use the code below to create a `new_york_addresses` table & import the address data. The import will take longer than the tiny datasets we've loaded so far, because the CSV file is about 50MB.\n",
    "\n",
    "```\n",
    "CREATE TABLE new_york_addresses (\n",
    "    longitude numeric(9, 6),\n",
    "    latitude numeric(9, 6),\n",
    "    street_number text,\n",
    "    street text,\n",
    "    unit text,\n",
    "    postcode text,\n",
    "    id integer CONSTRAINT new_york_key PRIMARY KEY\n",
    ");\n",
    "\n",
    "COPY new_york_addresses\n",
    "FROM '/YourDirectory/city_of_new_york.csv'\n",
    "WITH (FORMAT CSV, HEADER);\n",
    "```\n",
    "\n",
    "When the data loads, run a quick `SELECT` query to visually check that you have 940,374 rows & 7 columns. \n",
    "\n",
    "<img src = \"Importing New York City Address Data.png\" width = \"600\" style = \"margin:auto\"/>\n",
    "\n",
    "A common use fo this data might be to search for matches in the `street` column, so we'll use that example for exploring index performance.\n",
    "\n",
    "### Benchmarking Query Performance with EXPLAIN\n",
    "\n",
    "We'll measure the performance before & after adding an index by using the PostgreSQL-specific `EXPLAIN` command, which lists the *query plan* for a specific database query. The query plan might include how the database plans to scan the table, whether or not it will use indexes, & so on. When we add the `ANALYZE` keyword, `EXPLAIN` will carry out the query & show the actual execution time.\n",
    "\n",
    "### Recording Some Control Execution Times\n",
    "\n",
    "We'll use the three querys below to analyse query performance before & after adding an index. We're using typical `SELECT` queries with a `WHERE` clause with `EXPLAIN ANALYSE` included at the beginning. These keywords tell the database to execute the query & display statistics about the query process & how long it took to execute, rather than show the results.\n",
    "\n",
    "```\n",
    "EXPLAIN ANALYZE SELECT * FROM new_york_addresses\n",
    "WHERE street = 'BROADWAY';\n",
    "\n",
    "EXPLAIN ANALYZE SELECT * FROM new_york_addresses\n",
    "WHERE street = '52 STREET';\n",
    "\n",
    "EXPLAIN ANALYSE SELECT * FROM new_york_addresses\n",
    "WHERE street = 'ZWICKY AVENUE';\n",
    "```\n",
    "\n",
    "On my system, the first query returns these stats in the pgAdmin output pane:\n",
    "\n",
    "<img src = \"Benchmark Queries for Index Performance.png\" width = \"600\" style = \"margin:auto\"/>\n",
    "\n",
    "Not all the output is relevant here, so I won't decode it all, but two lines are pertinent. The first indicates that to find any rows where `street = 'BROADWAY'`, the database will conduct a sequential scan of the table. That's a synonym for a full table scan: the database will examine each row & remove any where `street` doesn't match `BROADWAY`. The execution time is how long the query took to run. Your time will depend on factors including your computer hardware.\n",
    "\n",
    "For the test, run each query several times & record the fastest execution time for each. You'll notice that execution times for the same query will vary slightly on each run. That can be the result of several factors, from other processes running on the server to the effect of data being held in memory after a prior run of the query.\n",
    "\n",
    "### Adding the Index\n",
    "\n",
    "Now, let's see how adding an index changes the query's search method & execution time. The code below shows a SQL statement for creating the index with PostgreSQL:\n",
    "\n",
    "```\n",
    "CREATE INDEX street_idx\n",
    "ON new_york_addresses (street);\n",
    "```\n",
    "\n",
    "Notice that it's similar to the commands for creating constraints. We give the `CREATE INDEX` keywords followed by a name we choose for the index, in this case `street_idx`. Then `ON` is added, followed by the target table & column.\n",
    "\n",
    "Execute the `CREATE INDEX` statement, & PostgreSQL will scan the values in the `street` column & build the index from them. We need to create the index only once. When the task finishes, rerun each of the three queries from before & record the execution times reported by `EXPLAIN ANALYZE`.\n",
    "\n",
    "<img src = \"Creating B-Tree Index on new_york_addresses Table.png\" width = \"600\" style = \"margin:auto\"/>\n",
    "\n",
    "Do you notice a change? First, we see that the database is now using an index scan on `street_idx` instead of visiting each row in a sequential scan. Also, the query speed is markedly faster.\n",
    "\n",
    "If you ever need to remove an index from a table -- perhaps if you're testing the performance of several index types -- use the `DROP INDEX` command followed by the name of the index to remove.\n",
    "\n",
    "## Considerations When Using Indexes\n",
    "\n",
    "We've seen that indexes have signficant performance benefits, so does that mean we should add an index to every column in a table? Not so fast! Indexes are valuable, but they're not always needed. In addition, they do enlarge the database & impose a maintenance cost on writing data. Here are a few tips for judging when to use indexes:\n",
    "\n",
    "1. Consult the documentation for the database system you're using the learn about the kinds of indexes available & which to use on particular data types. PostgreSQL, for example, has 5 more index types in addition to B-tree. One, called GiST, is particularly suited to geometry data types. Full-text search also benefits from indexing.\n",
    "2. An index on a foreign key will help avoid an expensive sequential scan during a cascading delete.\n",
    "3. Add indexes to columns that will frequently end up in a query `WHERE` clause. As we've seen, search performance is significantly improved via indexes.\n",
    "4. Use `EXPLAIN ANALYZE` to test the performance under a variety of configurations. Optimization is a process! If an index isn't being used by the database -- & it's not backing up a primary key or other constraints -- we can drop it to reduce the size of our database & speed up inserts, updates, & deletes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf97961-0c1b-4993-a57c-9d6b6447d8e1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fb0c5f-24cd-447c-9578-8ab3f7ef5710",
   "metadata": {},
   "source": [
    "# Wrapping Up\n",
    "\n",
    "We're ready to ensure that the databases we build or inherit are best suited for collection & exploration of data. It's crucial to define constraints that match the data & the expectation of users by not allowing values that don't make sense, making sure values are filled in, & setting up proper relationships between tables. We also learned how to make our queries run faster & how to consistently organise our database objects."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
