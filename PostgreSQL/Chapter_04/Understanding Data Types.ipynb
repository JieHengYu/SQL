{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0c8f92d-9e58-4a26-bed3-d2752b336332",
   "metadata": {},
   "source": [
    "# Understanding Data Types\n",
    "\n",
    "In a SQL database, each column in a table can only hold one data type, which you define in the `CREATE TABLE` statement by decalring the data type after the column name. In the following simple example table, you will find columns with three different data types: a date, an integers, & text.\n",
    "\n",
    "```\n",
    "CREATE TABLE eagle_watch (\n",
    "    observation_date date,\n",
    "    eagles_seen integer,\n",
    "    notes text\n",
    ")\n",
    "```\n",
    "\n",
    "In this table named `eagle_watch` (for a hypothetical inventory of bald eagles), we declare the `observation_date` column to hold date values by adding the `date` type declaration after its name. Similarly, we set `eagles_seen` to hold whole numbers with the `integer` type declaration & declare `notes` to hold characters via the `text` type.\n",
    "\n",
    "These data types fall into the three categories you'll encounter most:\n",
    "\n",
    "1. **Characters**: any character or symbol\n",
    "2. **Numbers**: includes whole numbers & fractions\n",
    "3. **Dates & Times**: temporal information\n",
    "\n",
    "We'll look at each data type in depth, noting whether they're part of ANSI SQL standards or specific to PostgreSQL along the way. You can find an in-depth look at where PostgreSQL deviates from the SQL standard [here](https://wiki.postgresql.org/wiki/PostgreSQL_vs_SQL_Standard)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1c841d-965e-4746-bb57-2a52b410b65d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33411279-4865-4151-a901-006f27395987",
   "metadata": {},
   "source": [
    "# Understanding Characters\n",
    "\n",
    "*Character string types* are general-purpose types suitable for any combination of text, numbers, & symbols. Character types include the following:\n",
    "\n",
    "1. **char(n)**\n",
    "   - A fixed-length column where the character is specified by `n`. A column set at `char(20)` stores 20 characters per row regardless of how many characters you insert. If you insert fewer than 20 characters in any row, PostgreSQL pads the rest of the column with spaces. This type is part of standard SQL & can be specified with the longer name `character(n)` as well.\n",
    "3. **varchar(n)**\n",
    "   - A variable-length column where the *maximum* length is specified by `n`. If you insert fewer characters than the maximum, PostgreSQL will not store extra spaces. For example, the string `blue` will take four spaces, whereas the string `123` will take three. In large databases, this practice saves considerable space. This type is included in standard SQL & can also be specified using its longer name `character varying(n)`.\n",
    "5. **text**\n",
    "   - A variable-length column of unlimited length. The `text` type is not part of the SQL standard, but there are similar implementations in other database systems.\n",
    "\n",
    "There is no substantial difference in performance among these three types. But, the flexibility & potential space savings of `varchar` & `text` seem to give them an advantage. However, if you search discussions online, some users suggest that defining a column that will always have the same number of characters with `char` is a good way to signal what data it should contain. For example, you might see `char(2)` used for US state postal abbreviations.\n",
    "\n",
    "To see these three character types in action, run the below SQL script. It will build & load a simple table, then export it to a text file on your computer.\n",
    "\n",
    "```\n",
    "CREATE TABLE char_data_types (\n",
    "    char_column char(10),\n",
    "    varchar_column varchar(10),\n",
    "    text_column text\n",
    ");\n",
    "\n",
    "INSERT INTO char_data_types\n",
    "VALUES ('abc', 'abc', 'abc'),\n",
    "       ('defghi', 'defghi', 'defghi');\n",
    "\n",
    "COPY char_data_types TO 'C:/YourDirectory/typetest.txt'\n",
    "WITH (FORMAT CSV, HEADER, DELIMITER '|');\n",
    "```\n",
    "\n",
    "We define three character columns of different types & insert two rows of the same string into each. Unlike the `INSERT INTO` statement we learned in previous lessons, we're not specifying the names of the columns. If the `VALUES` statements match the number of columns in the table, the database will assume you're inserting values in the order the column definitions were specified in the table.\n",
    "\n",
    "Next, we use the PostgreSQL `COPY` keyword to export the data to a text file named *typetest.txt* in a directory you specify. For example, the path to the SQL folder where we downloaded the course materials for this lesson is */Users/jiehengyu/Desktop/SQL/Chapter_04*. The directory must exist already or else PostgreSQL won't create it for you.\n",
    "\n",
    "<img src = \"Character Data Types in Action.png\" width = \"600\" style = \"margin:auto\"/>\n",
    "\n",
    "In PostgreSQL, `COPY table_name FROM` is the import function, & `COPY table_name TO` is the export function. We'll cover these in more detail in the next lesson. All you need to know now is that the `WITH` keyword options will format the data in the file with each column separated by a *pipe* (|) character. That way, you can easily see where spaces fill out the unused portions of the `char` column.\n",
    "\n",
    "To see the output, open *typetest.txt* using a text editor. The contents should look like this:\n",
    "\n",
    "```\n",
    "char_column|varchar_column|text_column\n",
    "abc       |abc|abc\n",
    "defghi    |defghi|defghi\n",
    "```\n",
    "\n",
    "Even though we specified 10 characters for both the `char` & `varchar` columns, only the `char` column outputs 10 characters in both rows, padding unused characters with spaces. The `varchar` & `text` columns store only the characters you inserted.\n",
    "\n",
    "Again, there's no real performance different among the three types, although this example shows that `char` consumes more storage space than needed. A few unused spaces in each column might seem negligible, but multiply that over millions of rows in dozens of tables & you'll soon wish you had been more economical."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b74d179-97b3-4b4b-b792-6e14db49931c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3728ed4b-0d9f-48ea-b939-eb1ff48acf81",
   "metadata": {},
   "source": [
    "# Understanding Numbers\n",
    "\n",
    "Number columns hold various types of (you guessed it) numbers, but that's not all: they also allow you to perform calculations on those numbers. That's an important distinction from members you store as strings in a character column, which can't be added, multiplied, divided, or perform any other math operation. Also, numbers stored as characters sort differently than numbers stored as numbers, so if you're doing math or the numeric order is important, use number types.\n",
    "\n",
    "The SQL number types include the following:\n",
    "\n",
    "1. **Integers**: whole numbers, both positive & negative\n",
    "2. **Fixed-point & floating-point**: two formats of fractions of whole numbers\n",
    "\n",
    "We'll look at each type separately.\n",
    "\n",
    "## Using Integers\n",
    "\n",
    "The integer data types are the most common number types you'll find when exploring a SQL database. These are *whole numbers*, both positive & negative, including zero. Think of all the places integers appear in life: your street or apartment number, the serial number on your refrigerator, the number on a raffle ticket.\n",
    "\n",
    "The SQL standard provides three integer types: `smallint`, `integer`, & `bigint`. The difference between the three types is the maximum size of the numbers they can hold. The table below shows the upper & lower limits of each, as well as how much storage each requires in bytes.\n",
    "\n",
    "|Data type|Storage size|Range|\n",
    "|:---|:---|:---|\n",
    "|`smallint`|2 bytes|-32768 to +32768|\n",
    "|`integer`|4 bytes|-2147483648 to +2147483648|\n",
    "|`bigint`|8 bytes|-9223372036854775808 to +9223372036854775808|\n",
    "\n",
    "The `bigint` type will cover just about any requirement you'll ever have with a number column, though it eats up the most storage. Its use is a must if you're working with numbers larger than about 2.1 billion, but you also can easily make it your go-to default & never worry about not being able to fit a number in the column. However, if you're confident numbers will remain within the `integer` limit, that type is a good choice because it doesn't consume as much space as `bigint` (a concern when dealing with millions of data rows).\n",
    "\n",
    "When you know that values will remain constrained, `smallint` makes sense: days of the month or years are good examples. The `smallint` type will use half the storage as `integer`, so it's a smart database design if the column values will always fit within its range.\n",
    "\n",
    "If you try to insert a number into any of these columns that is outside its range, the database will stop the operation & return an `out of range` error.\n",
    "\n",
    "## Auto-Incrementing Integers\n",
    "\n",
    "Sometimes, it's helpful to create a column that holds integers that *auto-increment* each time you add a row to the table. For example, you might use an auto-incrementing column to create a unique ID number, aslo known as a *primary key*, for each row in the table. Each row then has its own ID that other tables in the database can reference.\n",
    "\n",
    "With PostgreSQL, you have two ways to auto-increment an integer column. One is the *serial* data type, a PostgreSQL-specific implementation of the ANSI SQL standard for auto-numbered *identity columns*. The other is the ANSI SQL standard `IDENTITY` keyword. Let's start with serial.\n",
    "\n",
    "### Auto-Incrementing with Serial\n",
    "\n",
    "In the lesson when we made the `teachers` table, we created an `id` column with the declaration of `bigserial`: this & its siblings `smallserial` & `serial` are not so much true data types as special *implementation* of the corresponding *smallint*, *integer*, *bigint* types. When you add a column with a serial type, PostgreSQL will auto-increment the value each time you insert a row, starting with 1, up to the maximum of each integer.\n",
    "\n",
    "The table below shows the serialt ypes & the ranges they cover.\n",
    "\n",
    "|Data type|Storage size|Range|\n",
    "|:---|:---|:---|\n",
    "|`smallserial`|2 bytes|1 to 32767|\n",
    "|`serial`|4 bytes|1 to 2147483647|\n",
    "|`bigserial`|8 bytes|1 to 9223372036854775808|\n",
    "\n",
    "To use a serial type on a column, declare it in the `CREATE TABLE` statement as you would an integer type. For example, you could create a table called `people` that has an `id` column equivalent in size to the `integer` data type:\n",
    "\n",
    "```\n",
    "CREATE TABLE people (\n",
    "    id serial,\n",
    "    person_name varchar(100)\n",
    ");\n",
    "```\n",
    "\n",
    "### Auto-Incrementing with IDENTITY\n",
    "\n",
    "As of version 10, PostgreSQL include support for `IDENTITY`, the standard SQL implementation for auto-incrementing integers. The `IDENTITY` syntax is more verbose, but some database users prefer it for its cross-compatability wtih other database systems (such as Oracle) & also because it has an option to prevent users from accidently inserting values in the auto-incrementing column (which serial types will permit).\n",
    "\n",
    "You can specify `IDENTITY` in two ways:\n",
    "\n",
    "`GENERATED ALWAYS AS IDENTITY` tells the database to always fill the column with an auto-incremented value. A user cannot insert a value into the `id` column without manually overriding that setting. See the `OVERRIDING SYSTEM VALUE` section of the PostgreSQL `INSERT` documentation [here](https://www.postgresql.org/docs/current/sql-insert.html) for details.\n",
    "\n",
    "`GENERATED BY DEFAULT AS IDENTITY` tells the database to fill the column with an auto-incremented value by default if the user does not supply one.\n",
    "\n",
    "For now, we'll stick with the first option, using `ALWAYS`. To create a table called `people` that has an `id` column populated via `IDENTITY`, you would use this syntax:\n",
    "\n",
    "```\n",
    "CREATE TABLE people (\n",
    "    id integer GENERATED ALWAYS AS IDENTITY,\n",
    "    person_name varchar(100)\n",
    ");\n",
    "```\n",
    "\n",
    "For the `id` data type, we use `integer` followed by the keywords `GENERATED ALWAYS AS IDENTITY`. Now, every time we insert a `person_name` value into the table, the database will fill the `id` column with an auto-incremented value.\n",
    "\n",
    "Given its compatibility with the ANSI SQL standard, we'll use `IDENTITY` for the remainder of the course.\n",
    "\n",
    "<img src = \"Auto-Incrementing with IDENTITY.png\" width = \"600\" style = \"margin:auto\"/>\n",
    "\n",
    "## Using Decimal Numbers\n",
    "\n",
    "*Decimals* represent a whole number plus a fraction of a whole number; the fraction is represented by digits following a *decimal point*. In a SQL database, they're handled by *fixed-point* & *floating-point* data types. For example, if the distance from my house to the nearest grocer is 6.7 miles; I could insert 6.7 into either a fixed-point or floating-point column with no complaint from PostgreSQL. The only difference is how the computer stores the data.\n",
    "\n",
    "### Understanding Fixed-Point Numbers\n",
    "\n",
    "The fixed-point type, also called the *arbitrary precision* type, is `numeric(precision, scale)`. You give the argument `precision` as the maximum number of digits total in the decimal number, & the argument `scale` as the number of digits allowable on the right of the decimal point. Alternatively, you can specify this type using `decimal(precision, scale)`. Both are part of the ANSI SQL standard. If you omit specifying a scale value, the scale will set to zero; in effect, that creates an integer.\n",
    "\n",
    "For example, let's say we're working for the US National Weather Service, & we measure rainfall up to two decimal places. To record rainfall in a database using five digits total (the precision) & two digits maximum to the right of the decimal (the scale), we'd specify it as `numeric(5, 2)`. The database will always return two digits to the right of the decimal point, even if you don't enter a number that contains two digits such as 1.47, 1.00, & 121.50.\n",
    "\n",
    "### Understanding Floating-Point Types\n",
    "\n",
    "The two floating-point types are `real` & `double precision`, both part of the SQL standard. The difference between the two is how much data they store. The `real` type allows precision to six decimal digits, & `double precision` to 15 decimal digits of precision, both of which include the number of digits on both sides of the point. These floating-point types are also called *variable-precision* types. The database stores the number in parts representing the digits & an exponent -- the location where the decimal point belongs. So, unlike `numeric`, where we specify fixed precision & scale, the decimal point in a given column can \"float\" depending on the number.\n",
    "\n",
    "### Using Fixed- & Floating-Point Types\n",
    "\n",
    "Each type has differeing limits on the number of total digits, or precision, it can hold.\n",
    "\n",
    "|Data type|Storage size|Storage type|Range|\n",
    "|:---|:---|:---|:---|\n",
    "|`numeric, decimal`|Variable|Fixed-point|Up to 131,072 digits before the decimal point; up to 16,383 digits after the decimal point|\n",
    "|`real`|4 bytes|Floating-point|6 decimal digits precision|\n",
    "|`double precision`|8 bytes|Floating-point|15 decimal digits precision|\n",
    "\n",
    "To see how each of the three data types handles the same numbers, create a small table & insert a variety of test cases.\n",
    "\n",
    "```\n",
    "CREATE TABLE number_data_types (\n",
    "    numeric_column numeric(20, 5),\n",
    "    real_column real,\n",
    "    double_column double precision\n",
    ");\n",
    "\n",
    "INSERT INTO number_data_types\n",
    "VALUES (.7, .7, .7),\n",
    "       (2.13579, 2.13579, 2.13579),\n",
    "       (2.1357987654, 2.1357987654, 2.1357987654);\n",
    "\n",
    "SELECT * FROM number_data_types;\n",
    "```\n",
    "\n",
    "We create a table with one column for each of the fractional data types & load three rows into the table. Each row repeats the same number across all three columns. When the last line of the script runs & we select everything from the table, we get the following:\n",
    "\n",
    "<img src = \"Number Data Types in Action.png\" width = \"600\" style = \"margin:auto\"/>\n",
    "\n",
    "Notice what happened. The `numeric` column, set with a scale of five, stores five digits after the decimal point whether or not you inserted that many. If fewer than five, it pads the rest with zeros. If more than five, it rounds them -- as with the third-row number with 10 digits after the decimal.\n",
    "\n",
    "The `real` & `double precision` columns add no padding. On the third row, you see PostgreSQL's default behavior in those two columns, which is representation rather than show the entire value.\n",
    "\n",
    "### Running into Trouble with Floating-Point Math\n",
    "\n",
    "If you're thinking, \"Well, numbers stored as a floating-point look just like numbers stored as fixed,\" tread cautiously. The way computers store floating-point numbers can lead to unintented mathematical errors. Look at what happens when we do some calculations on these numbers.\n",
    "\n",
    "```\n",
    "SELECT numeric_column * 10000000 AS fixed,\n",
    "       real_column * 10000000 AS floating\n",
    "FROM number_data_types\n",
    "WHERE numeric_column = .7;\n",
    "```\n",
    "\n",
    "Here, we multiple the `numeric_column` & the `real_column` by 10 million & use a `WHERE` clause to filter out just the first row. We should get the same result for both calculations, right? Here's what the query returns:\n",
    "\n",
    "<img src = \"Rounding Issues with Float Columns.png\" width = \"600\" style = \"margin:auto\"/>\n",
    "\n",
    "No wonder floating-point types are referred to as \"inexact\". The reason floating-point math produces such errors is that the computer attempts to squeeze lots of information into a finite number of bits.\n",
    "\n",
    "The storage required by the `numeric` data type is variable, & depending on the precision & scale specified, `numeric` can consume considerably more space than the floating-point types. If you're working with millions of rows, it's worth considering whether you can live with relatively inexact floating-point math.\n",
    "\n",
    "## Choosing Your Number Data Type\n",
    "\n",
    "For now, there are three guidelines to consider when you're dealing with number data types. If you're working with decimal data & need calculations to be exact (dealing with money, for example), choose `numeric` or its equivalent, `decimal`. Float types will save space, but use them only when exactness is not as important.\n",
    "\n",
    "Choose a big enough number type. Unless you're designing a database to hold millions of rows, err on the side of bigger. When using `numeric` or `decimal`, set the precision large enough to accomodate the number of digits on both sides of the decimal point. With whole numbers, use `bigint` unless you're absolutely sure column values will be constrained to fit into the smaller `integer` or `smallint` type."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2e302a-9b84-451d-887a-4f2e8c201561",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9021b400-af70-46f9-9ea3-c20df3d56081",
   "metadata": {},
   "source": [
    "# Understanding Dates & Times\n",
    "\n",
    "PostgreSQL's date & time support includes the four major data types shown in the table below.\n",
    "\n",
    "|Data type|Storage size|Description|Range|\n",
    "|:---|:---|:---|:---|\n",
    "|`timestamp`|8 bytes|Date & time|4,713 BC to 294276 AD|\n",
    "|`date`|4 bytes|Date (no time)|4,713 BC to 5,874,897 AD|\n",
    "|`time`|8 bytes|Time (no date)|00:00:00 to 24:00:00|\n",
    "|`interval`|16 bytes|Time interval|+/- 178,000,000 years|\n",
    "\n",
    "Here's a rundown of data types for times & dates in PostgreSQL:\n",
    "\n",
    "**timestamp:** records date & time, which are useful for a range of situations you might track: departures & arrivals of passenger flights, a schedule of Major League Baseball games, or incidents along a timeline. You will almost always want to add the keywords `with time zone` to ensure that the time recorded for an event includes the time zone where it occurred. Otherwise, times recorded in various places around the globe become impossible to compare. The format `timestamp with time zone` is part of the SQL standard; with PostgreSQL, you can specify the same data type using `timestamptz`.\n",
    "\n",
    "**date:** records just the date; part of the SQL standard.\n",
    "\n",
    "**time:** records just the time & is part of the SQL standard. You can add the `with time zone` keywords; without a date, the time zone will be meaningless.\n",
    "\n",
    "**interval:** holds a value representing a unit of time expressed in the format `quantity unit`. It doesn't record the start or end of a time period, only its length (Ex: `12 days` or `8 hours`). The [PostgreSQL documentation](https://www.postgresql.org/docs/current/datatype-datetime.html) lists unit values ranging from `microsecond` to `millennium`. You'll typically use this type for calculations or filtering on other date & time columns. It is a part of the SQL standard.\n",
    "\n",
    "Let's focus on the `timestamp with time zone` & `interval` types. To see this in action, run the below SQL script:\n",
    "\n",
    "```\n",
    "CREATE TABLE date_time_types (\n",
    "    timestamp_column timestamp with time zone,\n",
    "    interval_column interval\n",
    ");\n",
    "\n",
    "INSERT INTO date_time_types\n",
    "VALUES ('2022-12-31 01:00 EST', '2 days'),\n",
    "       ('2022-12-31 01:00 -8', '1 month'),\n",
    "       ('2022-12-31 01:00 Australia/Melbourne', '1 century'),\n",
    "       (now(), '1 week');\n",
    "\n",
    "SELECT * FROM date_time_types;\n",
    "```\n",
    "\n",
    "Here, we create a table with a column for both types & insert four rows. For the first three rows, our insert for the `timestamp_column` uses the same date & time (December 31, 2022 at 1 AM) using the International Organisation for Standardisation (ISO) format for dates & times: `YYYY-MM-DD HH:MM:SS`. Following the time, we specify a time zone but use a different format in each of the first three rows: in the first row, we use the abbreviation `EST`, which is Eastern standard time in the United States. In the second row, we set the time zone with the value `-8`. That represents the number of hours difference, or *offset*, from the Coordinated Universal Time (UTC),the time standard for the world. The value of UTC is +/- 00:00, so `-8` specifies a time zone eight hours behind UTC. In the United States, when daylight saving time is in effect, `-8` is the value for the Alaska time zone. From November through to early March, when the United States reverts to standard time, it refers to the Pacific time zone. For the third row, we specify the time zone using the name of an area & location: `Australia/Melbourne`. In the fourth location, instead of specifying dates, times, & timezones, the script uses PostgreSQL's `now()` function to capture the current transaction time from your hardware.\n",
    "\n",
    "After the script runs, the output should look similar to this:\n",
    "\n",
    "<img src = \"timestamp & interval Types in Action.png\" width = \"600\" style = \"margin:auto\"/>\n",
    "\n",
    "Even though we supplied the same date & time in the first three rows on the `timestamp_column`, each row's output differs. The reason is that pgAdmin reports the date & time relative to my time zone, which in the results shown is indicated by the UTC offset of `-08` at the end of the timestamp. A UTC offset of `-08` means eight hours behind UTC, equivalent to the US Pacific time zone during fall & winter months when standard time is observed. If you live in a different time zone, you'll likely see a different offset.\n",
    "\n",
    "Finally, the `interval_column` shows the values you entered. PostgreSQL changed `1 century` to `100 years` & `1 week` to `7 days` because that is its preferred settings for interval display."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7145a62-9a92-4e31-bba1-4dfb156c4af7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e6d159-39bc-4e2f-a768-b4049b2fd4ed",
   "metadata": {},
   "source": [
    "# Using the interval Data Type in Calculations\n",
    "\n",
    "The `interval` data type is useful for easy-to-understand calculations on date & time data. For example, let's say you have a column that holds the date a client signed a contract. Using interval data, you can add 90 days to each contract date to determine when to follow up with the client.\n",
    "\n",
    "To see how the `interval` data type works, we'll use the `date_time_types` table we just created.\n",
    "\n",
    "```\n",
    "SELECT timestamp_column, interval_column,\n",
    "       timestamp_column - interval_column AS new_date\n",
    "FROM date_time_types;\n",
    "```\n",
    "\n",
    "This is a typical `SELECT` statement, except we compute a column called `new_date` that contains the result of `timestamp_column` minus `interval_column` (Computed columns are called *expressions*). In each row, we subtract the unit of time indicated by the `interval` data type from the date. This produces the following result:\n",
    "\n",
    "<img src = \"Using the interval Data Type.png\" width = \"600\" style = \"margin:auto\"/>\n",
    "\n",
    "Note that the `new_date` column by default is formatted as type `timestamp with time zone`, allowing for the display of time values as well as dates if the interval values uses them. You can see the data type listed in the pgAdmin results grid, beneath the column names. Again, your output may be different, based on your time zone."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52a4f59-d4f5-4396-a2ff-dcd81330411e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d69eb12-7c58-4b40-855f-79ca88d95d7e",
   "metadata": {},
   "source": [
    "# Understanding JSON & JSONB\n",
    "\n",
    "JSON, short for *JavaScript Object Notation*, is a structured data format used for both storing data & exchanging data between computer systems. All major programming languages support reading & writing data in JSON format, which organises information in a collection of *key/value* pairs as well as lists of values. Here's a simple example:\n",
    "\n",
    "```\n",
    "{\"business_name\": \"Old Ebbitt Grill\",\n",
    " \"business_type\": \"Restaurant\",\n",
    " \"employees\": 300,\n",
    " \"address\": {\"street\": \"576 15th St NW\",\n",
    "             \"city\": \"Washington\",\n",
    "             \"state\": \"DC\",\n",
    "             \"zip_code\": \"20005\"}\n",
    "}\n",
    "```\n",
    "\n",
    "This snippet of JSON shows the format's basic structure. A *key*, for example `business_name`, is associated with a *value* -- in this case, `Old Ebbitt Grill`. A key also can have as its value a collection of additional key/value pairs, as shown with `address`. The JSON standard enforces rules about formatting, such as separating keys & values with a colon & enclosing key names in double quotes.\n",
    "\n",
    "PostgreSQL currently offers two data types for JSON, both of which enforce valid JSON & support fcuntions for working with data in that format:\n",
    "\n",
    "**json:** stores an exact copy of the JSON text\n",
    "\n",
    "**jsonb:** stores the JSON text in a binary format\n",
    "\n",
    "JSON entered the SQL standard in 2016, but PostgreSQL added support several years earlier, starting with version 9.2. PostgreSQL currently implements several functions found in the SQL standard, but offers its own additional JSON functions & operators. We'll cover these in later lessons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e386c16-e73d-45b8-9b9b-ff8907dc86d1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28110830-82d5-4bf6-9fda-5c6883c765d4",
   "metadata": {},
   "source": [
    "# Using Miscellaneous Types\n",
    "\n",
    "Character, number & date/time types will likely comprise the bulk of the work you do with SQL. But PostgreSQL supports many additional types, including but not limited to the following:\n",
    "\n",
    "1. A *Boolean* type that stores a value of `true` or `false`\n",
    "2. *Geometric types* that include points, lines, circles, & other two-dimensional objects\n",
    "3. *Text search types* for PostgreSQL's full-text search engine\n",
    "4. *Network address types*, such as IP or MAC addresses\n",
    "5. A *universally unique identifier* (UUID) type, sometimes used as a unique key value in tables\n",
    "6. *Range* types, which lets you specify a range of values, such a integers or time stamps\n",
    "7. Types for storing *binary* data\n",
    "8. An *XML* data type that stores infromation in that structured format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cdafc6-a6cb-4ce2-932a-8ab134218846",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d953b0f-ed38-4aeb-b557-eff6641133d1",
   "metadata": {},
   "source": [
    "# Transforming Values from One Type to Another with CAST\n",
    "\n",
    "Occasionally, you mayneed to transform a value from its stored data type to another type. For example, you may want to retrieve a number as a character so you can combine it with text. You can perform conversions using the `CAST()` function.\n",
    "\n",
    "The `CAST()` function succeeds only when the target data type can accommodate the original value. Casting an integer as text is possible because the character types can include numbers. Casting text with letters of the alphabet as a number is not.\n",
    "\n",
    "The below SQL code shows three examples using three data type tables we just created. The first two examples work, but the third will try to perform an invalid type conversion so you can see what a type casting error looks like.\n",
    "\n",
    "```\n",
    "SELECT timestamp_column,\n",
    "       CAST(timestamp_column as varchar(10))\n",
    "FROM date_time_types;\n",
    "\n",
    "SELECT numeric_column,\n",
    "       CAST(numeric_column AS integer),\n",
    "       CAST(numeric_column AS text)\n",
    "FROM number_data_types;\n",
    "\n",
    "SELECT CAST(char_column AS integer)\n",
    "FROM char_data_types;\n",
    "```\n",
    "\n",
    "The first `SELECT` statement returns the `timestamp_column` value as a `varchar`, which you'll recall is a variable-length character column. In this case, we set the character length to 10, which means when converted to a character string, only the first 10 characters a kept. That is handy in this case, because that just gives us the date segment of the column & excludes the time. \n",
    "\n",
    "<img src = \"CAST Example 1.png\" width = \"600\" style = \"margin:auto\"/>\n",
    "\n",
    "The second `SELECT` statement returns the `numeric_column` value three times: in its original form & then as an integer & as `text`. Upon conversion to an integer, PostgreSQL rounds the value to a whole number. But with the `text` conversion, no rounding occurs.\n",
    "\n",
    "<img src = \"CAST Example 2.png\" width = \"600\" style = \"margin:auto\"/>\n",
    "\n",
    "The final `SELECT` statement doesn't work: it returns an error of `invalid input syntax for type integer` because letters can't become integers.\n",
    "\n",
    "<img src = \"CAST Example 3.png\" width = \"600\" style = \"margin:auto\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71271384-1eea-4235-844e-de379ffd8faa",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedc38ea-3528-4fd0-a4d4-b7acff9e8757",
   "metadata": {},
   "source": [
    "# Using CAST Shortcut Notation\n",
    "\n",
    "It's always best to write SQL in a way that can be read by another person who might pick it up later. The way `CAST()` is written makes what you intend when you use it fairly obvious. However, PostgreSQL also offers a less obvious shortcut notation that takes less space: the *double colon*.\n",
    "\n",
    "Insert the double colon in between the name of the column & the data type you want to convert it to. For example, we can cast `timestamp_column` as `varchar`:\n",
    "\n",
    "```\n",
    "SELECT timestamp_column::varchar(10)\n",
    "FROM date_time_types;\n",
    "```\n",
    "\n",
    "<img src = \"CAST Shortcut Notation.png\" width = \"600\" style = \"margin:auto\"/>\n",
    "\n",
    "Use whichever suits you, but be aware that the double colon is a PostgreSQL-only implementation not found in other SQL variants."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93e6756-365e-43a9-b2be-201e48a2f1cb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600317ae-9919-4907-a9ec-60a89f416d01",
   "metadata": {},
   "source": [
    "# Wrapping Up\n",
    "\n",
    "You're now equipped to better understand the nuances of the data formats you encounter while digging into databases. If you come across monetary values stored as floating-point numbers, you'll be sure to convert them to decimals before performing any math. You'll also know how to use the right kind of text column to keep your databases from growing too big."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
